#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Consistent Truth Detector
AI ì¼ê´€ì„± ìˆëŠ” ì§„ì‹¤ì„± íƒì§€ê¸°

ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•´ í•­ìƒ ê°™ì€ ì§„ì‹¤ì„± ì ìˆ˜ë¥¼ ë°˜í™˜í•˜ëŠ” ê²°ì •ë¡ ì  ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import hashlib
import json
import re
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ConsistentAnalysisResult:
    """ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ ê²°ê³¼"""
    statement: str
    statement_hash: str
    truth_percentage: float
    confidence: float
    needs_correction: bool
    corrected_statement: str
    analysis_timestamp: datetime
    consistency_score: float
    analysis_method: str

class AIConsistentDetector:
    """AI ì¼ê´€ì„± ìˆëŠ” ì§„ì‹¤ì„± íƒì§€ê¸°"""
    
    def __init__(self):
        # ê²°ì •ë¡ ì  íŒ¨í„´ë“¤
        self.truth_patterns = {
            'scientific_facts': [
                (r'ì§€êµ¬.*ë‘¥ê¸€|ì§€êµ¬.*êµ¬í˜•', 0.95, 'ì§€êµ¬ëŠ” êµ¬í˜•ì…ë‹ˆë‹¤'),
                (r'ë¬¼.*100ë„.*ë“', 0.95, 'ë¬¼ì€ 100ë„ì—ì„œ ë“ìŠµë‹ˆë‹¤'),
                (r'1\s*\+\s*1\s*=\s*2', 0.98, '1 + 1 = 2ì…ë‹ˆë‹¤'),
                (r'íƒœì–‘.*ì¤‘ì‹¬', 0.95, 'íƒœì–‘ê³„ì˜ ì¤‘ì‹¬ì€ íƒœì–‘ì…ë‹ˆë‹¤'),
                (r'ì¤‘ë ¥.*ì¡´ì¬', 0.95, 'ì¤‘ë ¥ì€ ì¡´ì¬í•©ë‹ˆë‹¤'),
                (r'DNA.*êµ¬ì¡°', 0.90, 'DNAëŠ” ì´ì¤‘ ë‚˜ì„  êµ¬ì¡°ì…ë‹ˆë‹¤')
            ],
            'mathematical_facts': [
                (r'2\s*\+\s*2\s*=\s*4', 0.98, '2 + 2 = 4ì…ë‹ˆë‹¤'),
                (r'10\s*/\s*2\s*=\s*5', 0.98, '10 / 2 = 5ì…ë‹ˆë‹¤'),
                (r'3\s*\*\s*3\s*=\s*9', 0.98, '3 * 3 = 9ì…ë‹ˆë‹¤'),
                (r'âˆš4\s*=\s*2', 0.98, 'âˆš4 = 2ì…ë‹ˆë‹¤')
            ],
            'historical_facts': [
                (r'ì„¸ê³„ëŒ€ì „.*ë°œìƒ', 0.90, 'ì„¸ê³„ëŒ€ì „ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤'),
                (r'ì¸ë¥˜.*ì§„í™”', 0.85, 'ì¸ë¥˜ëŠ” ì§„í™”í–ˆìŠµë‹ˆë‹¤'),
                (r'ë¬¸ëª….*ë°œì „', 0.80, 'ë¬¸ëª…ì´ ë°œì „í–ˆìŠµë‹ˆë‹¤')
            ],
            'false_statements': [
                (r'ì§€êµ¬.*í‰í‰', 0.05, 'ì§€êµ¬ëŠ” í‰í‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'),
                (r'ë¬¼.*200ë„.*ë“', 0.05, 'ë¬¼ì€ 200ë„ì—ì„œ ë“ì§€ ì•ŠìŠµë‹ˆë‹¤'),
                (r'1\s*\+\s*1\s*=\s*3', 0.02, '1 + 1 = 3ì´ ì•„ë‹™ë‹ˆë‹¤'),
                (r'íƒœì–‘.*ì§€êµ¬.*ì¤‘ì‹¬', 0.05, 'íƒœì–‘ì´ ì§€êµ¬ ì¤‘ì‹¬ì´ ì•„ë‹™ë‹ˆë‹¤')
            ]
        }
        
        # ê³¼ì¥ í‘œí˜„ íŒ¨í„´ë“¤
        self.exaggeration_patterns = [
            (r'ì •ë§ë¡œ.*ì™„ì „íˆ.*ì ˆëŒ€ì ìœ¼ë¡œ', 0.3, 'ê³¼ë„í•œ í™•ì‹  í‘œí˜„'),
            (r'100%.*í™•ì‹¤', 0.2, 'ê³¼ë„í•œ í™•ì‹  í‘œí˜„'),
            (r'ì ˆëŒ€ì ìœ¼ë¡œ.*ì˜ì‹¬ì˜.*ì—¬ì§€ê°€.*ì—†', 0.1, 'ê³¼ë„í•œ í™•ì‹  í‘œí˜„'),
            (r'ë§¤ìš°.*ì—„ì²­.*ì •ë§', 0.4, 'ê³¼ì¥ í‘œí˜„'),
            (r'ì™„ì „íˆ.*ëª¨ë“ .*í•­ìƒ', 0.3, 'ê³¼ì¥ í‘œí˜„')
        ]
        
        # ëª¨ìˆœ í‘œí˜„ íŒ¨í„´ë“¤
        self.contradiction_patterns = [
            (r'ëª¨ë“ .*ì¼ë¶€', 0.2, 'ëª¨ìˆœëœ í‘œí˜„'),
            (r'í•­ìƒ.*ë•Œë•Œë¡œ', 0.2, 'ëª¨ìˆœëœ í‘œí˜„'),
            (r'ì™„ì „íˆ.*ë¶€ë¶„ì ', 0.2, 'ëª¨ìˆœëœ í‘œí˜„'),
            (r'ì ˆëŒ€.*ìƒëŒ€ì ', 0.2, 'ëª¨ìˆœëœ í‘œí˜„')
        ]
        
        # ê²°ê³¼ ìºì‹œ
        self.result_cache = {}
    
    def analyze_statement(self, statement: str, context: str = "") -> ConsistentAnalysisResult:
        """ì¼ê´€ì„± ìˆëŠ” ë¬¸ì¥ ë¶„ì„"""
        # ë¬¸ì¥ í•´ì‹œ ìƒì„± (ì¼ê´€ì„± ë³´ì¥)
        statement_hash = self._generate_statement_hash(statement, context)
        
        # ìºì‹œì—ì„œ ê²°ê³¼ í™•ì¸
        if statement_hash in self.result_cache:
            cached_result = self.result_cache[statement_hash]
            logger.info(f"ìºì‹œì—ì„œ ê²°ê³¼ ë°˜í™˜: {statement_hash[:8]}...")
            return cached_result
        
        # ìƒˆë¡œìš´ ë¶„ì„ ìˆ˜í–‰
        result = self._perform_consistent_analysis(statement, context, statement_hash)
        
        # ê²°ê³¼ ìºì‹œì— ì €ì¥
        self.result_cache[statement_hash] = result
        
        return result
    
    def _generate_statement_hash(self, statement: str, context: str) -> str:
        """ë¬¸ì¥ í•´ì‹œ ìƒì„± (ì¼ê´€ì„± ë³´ì¥)"""
        # ë¬¸ì¥ ì •ê·œí™”
        normalized_statement = self._normalize_statement(statement)
        normalized_context = self._normalize_statement(context)
        
        # í•´ì‹œ ìƒì„±
        content = f"{normalized_statement}|{normalized_context}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def _normalize_statement(self, text: str) -> str:
        """ë¬¸ì¥ ì •ê·œí™”"""
        if not text:
            return ""
        
        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower()
        
        # ê³µë°± ì •ê·œí™”
        text = re.sub(r'\s+', ' ', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
        text = re.sub(r'[^\w\sê°€-í£]', '', text)
        
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
    def _perform_consistent_analysis(self, statement: str, context: str, statement_hash: str) -> ConsistentAnalysisResult:
        """ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ ìˆ˜í–‰"""
        # 1. ê³¼í•™ì  ì‚¬ì‹¤ ê²€ì¦
        scientific_score = self._check_scientific_facts(statement)
        
        # 2. ìˆ˜í•™ì  ì‚¬ì‹¤ ê²€ì¦
        mathematical_score = self._check_mathematical_facts(statement)
        
        # 3. ì—­ì‚¬ì  ì‚¬ì‹¤ ê²€ì¦
        historical_score = self._check_historical_facts(statement)
        
        # 4. ê±°ì§“ ë¬¸ì¥ ê²€ì¦
        false_score = self._check_false_statements(statement)
        
        # 5. ê³¼ì¥ í‘œí˜„ ê²€ì¦
        exaggeration_penalty = self._check_exaggeration(statement)
        
        # 6. ëª¨ìˆœ í‘œí˜„ ê²€ì¦
        contradiction_penalty = self._check_contradiction(statement)
        
        # 7. ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê²°ì •ë¡ ì )
        base_score = max(scientific_score, mathematical_score, historical_score)
        
        # ê±°ì§“ ë¬¸ì¥ì´ë©´ ë‚®ì€ ì ìˆ˜
        if false_score < 0.5:
            base_score = min(base_score, false_score)
        
        # ê³¼ì¥ ë° ëª¨ìˆœ íŒ¨ë„í‹° ì ìš©
        final_score = base_score - exaggeration_penalty - contradiction_penalty
        final_score = max(0.0, min(1.0, final_score))
        
        # êµì • í•„ìš”ì„± íŒë‹¨
        needs_correction = final_score < 0.7 or exaggeration_penalty > 0.3 or contradiction_penalty > 0.2
        
        # êµì •ëœ ë¬¸ì¥ ìƒì„±
        corrected_statement = self._generate_corrected_statement(statement, base_score, exaggeration_penalty, contradiction_penalty)
        
        # ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
        consistency_score = self._calculate_consistency_score(statement, final_score)
        
        return ConsistentAnalysisResult(
            statement=statement,
            statement_hash=statement_hash,
            truth_percentage=final_score,
            confidence=consistency_score,
            needs_correction=needs_correction,
            corrected_statement=corrected_statement,
            analysis_timestamp=datetime.now(),
            consistency_score=consistency_score,
            analysis_method="deterministic_pattern_matching"
        )
    
    def _check_scientific_facts(self, statement: str) -> float:
        """ê³¼í•™ì  ì‚¬ì‹¤ ê²€ì¦"""
        for pattern, score, correction in self.truth_patterns['scientific_facts']:
            if re.search(pattern, statement, re.IGNORECASE):
                return score
        return 0.5  # ì¤‘ë¦½ ì ìˆ˜
    
    def _check_mathematical_facts(self, statement: str) -> float:
        """ìˆ˜í•™ì  ì‚¬ì‹¤ ê²€ì¦"""
        for pattern, score, correction in self.truth_patterns['mathematical_facts']:
            if re.search(pattern, statement, re.IGNORECASE):
                return score
        return 0.5  # ì¤‘ë¦½ ì ìˆ˜
    
    def _check_historical_facts(self, statement: str) -> float:
        """ì—­ì‚¬ì  ì‚¬ì‹¤ ê²€ì¦"""
        for pattern, score, correction in self.truth_patterns['historical_facts']:
            if re.search(pattern, statement, re.IGNORECASE):
                return score
        return 0.5  # ì¤‘ë¦½ ì ìˆ˜
    
    def _check_false_statements(self, statement: str) -> float:
        """ê±°ì§“ ë¬¸ì¥ ê²€ì¦"""
        for pattern, score, correction in self.truth_patterns['false_statements']:
            if re.search(pattern, statement, re.IGNORECASE):
                return score
        return 0.5  # ì¤‘ë¦½ ì ìˆ˜
    
    def _check_exaggeration(self, statement: str) -> float:
        """ê³¼ì¥ í‘œí˜„ ê²€ì¦"""
        total_penalty = 0.0
        for pattern, penalty, description in self.exaggeration_patterns:
            if re.search(pattern, statement, re.IGNORECASE):
                total_penalty += penalty
        return min(0.5, total_penalty)  # ìµœëŒ€ 0.5 íŒ¨ë„í‹°
    
    def _check_contradiction(self, statement: str) -> float:
        """ëª¨ìˆœ í‘œí˜„ ê²€ì¦"""
        total_penalty = 0.0
        for pattern, penalty, description in self.contradiction_patterns:
            if re.search(pattern, statement, re.IGNORECASE):
                total_penalty += penalty
        return min(0.5, total_penalty)  # ìµœëŒ€ 0.5 íŒ¨ë„í‹°
    
    def _generate_corrected_statement(self, statement: str, base_score: float, exaggeration_penalty: float, contradiction_penalty: float) -> str:
        """êµì •ëœ ë¬¸ì¥ ìƒì„±"""
        if base_score >= 0.8 and exaggeration_penalty < 0.2 and contradiction_penalty < 0.2:
            return statement  # êµì • ë¶ˆí•„ìš”
        
        corrected = statement
        
        # ê³¼ì¥ í‘œí˜„ ì œê±°
        if exaggeration_penalty > 0.2:
            corrected = re.sub(r'ì •ë§ë¡œ.*ì™„ì „íˆ.*ì ˆëŒ€ì ìœ¼ë¡œ', 'ì¼ë°˜ì ìœ¼ë¡œ', corrected)
            corrected = re.sub(r'100%.*í™•ì‹¤', 'í™•ì‹¤', corrected)
            corrected = re.sub(r'ì ˆëŒ€ì ìœ¼ë¡œ.*ì˜ì‹¬ì˜.*ì—¬ì§€ê°€.*ì—†', 'í™•ì‹¤', corrected)
            corrected = re.sub(r'ë§¤ìš°.*ì—„ì²­.*ì •ë§', 'ìƒë‹¹íˆ', corrected)
            corrected = re.sub(r'ì™„ì „íˆ.*ëª¨ë“ .*í•­ìƒ', 'ëŒ€ë¶€ë¶„', corrected)
        
        # ëª¨ìˆœ í‘œí˜„ ìˆ˜ì •
        if contradiction_penalty > 0.2:
            corrected = re.sub(r'ëª¨ë“ .*ì¼ë¶€', 'ëŒ€ë¶€ë¶„', corrected)
            corrected = re.sub(r'í•­ìƒ.*ë•Œë•Œë¡œ', 'ìì£¼', corrected)
            corrected = re.sub(r'ì™„ì „íˆ.*ë¶€ë¶„ì ', 'ìƒë‹¹íˆ', corrected)
            corrected = re.sub(r'ì ˆëŒ€.*ìƒëŒ€ì ', 'ìƒëŒ€ì ', corrected)
        
        return corrected
    
    def _calculate_consistency_score(self, statement: str, truth_score: float) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        # ë¬¸ì¥ ê¸¸ì´ ê¸°ë°˜ ì¼ê´€ì„±
        length_consistency = min(1.0, len(statement) / 50.0)
        
        # ì ìˆ˜ ê¸°ë°˜ ì¼ê´€ì„±
        score_consistency = 1.0 - abs(truth_score - 0.5) * 2  # 0.5ì—ì„œ ë©€ìˆ˜ë¡ ì¼ê´€ì„± ë‚®ìŒ
        
        # ì¢…í•© ì¼ê´€ì„± ì ìˆ˜
        consistency = (length_consistency + score_consistency) / 2
        
        return max(0.5, min(1.0, consistency))
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        return {
            'cache_size': len(self.result_cache),
            'cache_hit_rate': getattr(self, '_cache_hits', 0) / max(1, getattr(self, '_total_requests', 1)),
            'total_requests': getattr(self, '_total_requests', 0),
            'cache_hits': getattr(self, '_cache_hits', 0)
        }
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.result_cache.clear()
        logger.info("ê²°ê³¼ ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” AI ì¼ê´€ì„± ìˆëŠ” ì§„ì‹¤ì„± íƒì§€ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    detector = AIConsistentDetector()
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_statements = [
        "ì§€êµ¬ëŠ” ë‘¥ê¸€ë‹¤.",
        "ì§€êµ¬ëŠ” ë‘¥ê¸€ë‹¤.",
        "ì§€êµ¬ëŠ” ë‘¥ê¸€ë‹¤.",
        "ë¬¼ì€ 100ë„ì—ì„œ ë“ëŠ”ë‹¤.",
        "ë¬¼ì€ 100ë„ì—ì„œ ë“ëŠ”ë‹¤.",
        "1 + 1 = 2ì´ë‹¤.",
        "1 + 1 = 2ì´ë‹¤.",
        "ì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤.",
        "ì§€êµ¬ëŠ” í‰í‰í•˜ë‹¤.",
        "ì •ë§ë¡œ ì™„ì „íˆ ì ˆëŒ€ì ìœ¼ë¡œ ëª¨ë“  ê²ƒì´ 100% ì§„ì‹¤ì´ë‹¤."
    ]
    
    print("ğŸ“ ë™ì¼í•œ ë¬¸ì¥ì— ëŒ€í•œ ì¼ê´€ì„± í…ŒìŠ¤íŠ¸:")
    print("-" * 40)
    
    for i, statement in enumerate(test_statements, 1):
        result = detector.analyze_statement(statement)
        
        print(f"{i:2d}. {statement}")
        print(f"    ì§„ì‹¤ì„±: {result.truth_percentage:.3f} | ì‹ ë¢°ë„: {result.confidence:.3f} | í•´ì‹œ: {result.statement_hash[:8]}...")
        if result.needs_correction:
            print(f"    êµì •: {result.corrected_statement}")
        print()
    
    # ìºì‹œ í†µê³„
    stats = detector.get_cache_stats()
    print(f"ğŸ“Š ìºì‹œ í†µê³„:")
    print(f"   ìºì‹œ í¬ê¸°: {stats['cache_size']}")
    print(f"   ìºì‹œ íˆíŠ¸ìœ¨: {stats['cache_hit_rate']:.2%}")
    print(f"   ì´ ìš”ì²­: {stats['total_requests']}")
    print(f"   ìºì‹œ íˆíŠ¸: {stats['cache_hits']}")

if __name__ == "__main__":
    main()

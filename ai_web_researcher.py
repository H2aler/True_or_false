#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Web Researcher
AI ì›¹ ì—°êµ¬ì›

AIê°€ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ì§„ì‹¤ì„±ì„ ê²€ì¦í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import requests
import re
import json
import time
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
from urllib.parse import quote, urljoin
from bs4 import BeautifulSoup
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼"""
    title: str
    url: str
    snippet: str
    source: str
    credibility_score: float
    relevance_score: float
    timestamp: datetime

@dataclass
class FactCheckResult:
    """ì‚¬ì‹¤ ê²€ì¦ ê²°ê³¼"""
    statement: str
    is_factual: bool
    confidence: float
    evidence: List[str]
    contradictory_sources: List[str]
    verification_method: str
    timestamp: datetime

@dataclass
class AnswerResult:
    """ë‹µë³€ ê²°ê³¼"""
    question: str
    answer: str
    confidence: float
    sources: List[SearchResult]
    fact_checks: List[FactCheckResult]
    reasoning: str
    timestamp: datetime

class AIWebResearcher:
    """AI ì›¹ ì—°êµ¬ì›"""
    
    def __init__(self):
        self.search_engines = {
            'google': self._search_google,
            'bing': self._search_bing,
            'duckduckgo': self._search_duckduckgo
        }
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ë„ë©”ì¸ë“¤
        self.credible_domains = [
            'wikipedia.org', 'britannica.com', 'nasa.gov', 'nih.gov',
            'who.int', 'cdc.gov', 'nature.com', 'science.org',
            'reuters.com', 'ap.org', 'bbc.com', 'cnn.com',
            'nytimes.com', 'washingtonpost.com', 'theguardian.com',
            'scientificamerican.com', 'nationalgeographic.com',
            'mayoclinic.org', 'webmd.com', 'harvard.edu',
            'mit.edu', 'stanford.edu', 'berkeley.edu'
        ]
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì†ŒìŠ¤ ë„ë©”ì¸ë“¤
        self.suspicious_domains = [
            'conspiracy.com', 'truth.com', 'realnews.com',
            'alternative.com', 'hidden.com', 'secret.com'
        ]
        
        # ì‚¬ì‹¤ ê²€ì¦ íŒ¨í„´ë“¤
        self.fact_check_patterns = {
            'scientific_facts': [
                r'ì§€êµ¬.*ë‘¥ê¸€', r'ë¬¼.*100ë„.*ë“', r'1\s*\+\s*1\s*=\s*2',
                r'íƒœì–‘.*ì¤‘ì‹¬', r'ì¤‘ë ¥.*ì¡´ì¬', r'DNA.*êµ¬ì¡°'
            ],
            'historical_facts': [
                r'ì„¸ê³„ëŒ€ì „.*ë°œìƒ', r'ì¸ë¥˜.*ì§„í™”', r'ë¬¸ëª….*ë°œì „'
            ],
            'medical_facts': [
                r'ë°±ì‹ .*íš¨ê³¼', r'ì„¸ê· .*ì§ˆë³‘', r'ì˜í•™.*ë°œì „'
            ]
        }
        
        # í—¤ë” ì„¤ì • (ë´‡ íƒì§€ íšŒí”¼)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
    
    def research_question(self, question: str, max_sources: int = 5) -> AnswerResult:
        """ì§ˆë¬¸ì— ëŒ€í•œ ì—°êµ¬ ìˆ˜í–‰"""
        logger.info(f"ì§ˆë¬¸ ì—°êµ¬ ì‹œì‘: {question}")
        
        # 1. ì§ˆë¬¸ ë¶„ì„ ë° ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        search_keywords = self._generate_search_keywords(question)
        
        # 2. ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
        search_results = []
        for keyword in search_keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
            results = self._search_web(keyword, max_results=3)
            search_results.extend(results)
        
        # 3. ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ ë° ì‹ ë¢°ë„ í‰ê°€
        search_results = self._evaluate_sources(search_results)
        search_results = sorted(search_results, key=lambda x: x.credibility_score, reverse=True)[:max_sources]
        
        # 4. ì‚¬ì‹¤ ê²€ì¦ ìˆ˜í–‰
        fact_checks = []
        for result in search_results:
            fact_check = self._verify_facts(result.snippet)
            if fact_check:
                fact_checks.append(fact_check)
        
        # 5. ë‹µë³€ ìƒì„±
        answer, confidence, reasoning = self._generate_answer(question, search_results, fact_checks)
        
        return AnswerResult(
            question=question,
            answer=answer,
            confidence=confidence,
            sources=search_results,
            fact_checks=fact_checks,
            reasoning=reasoning,
            timestamp=datetime.now()
        )
    
    def _generate_search_keywords(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""
        # ê¸°ë³¸ í‚¤ì›Œë“œ
        keywords = [question]
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í‚¤ì›Œë“œ ì¶”ê°€
        if any(word in question for word in ['ë¬´ì—‡', 'ë­', 'what']):
            keywords.append(question.replace('ë¬´ì—‡', '').replace('ë­', '').strip())
        
        if any(word in question for word in ['ì–¸ì œ', 'when']):
            keywords.append(question + ' ë‚ ì§œ ì‹œê°„')
        
        if any(word in question for word in ['ì–´ë””', 'where']):
            keywords.append(question + ' ìœ„ì¹˜ ì¥ì†Œ')
        
        if any(word in question for word in ['ì™œ', 'ì–´ë–»ê²Œ', 'why', 'how']):
            keywords.append(question + ' ì´ìœ  ì›ì¸')
        
        # ì˜ì–´ í‚¤ì›Œë“œë„ ì¶”ê°€
        if not any(ord(char) > 127 for char in question):  # í•œê¸€ì´ ì—†ëŠ” ê²½ìš°
            keywords.append(question + ' facts information')
        
        return keywords
    
    def _search_web(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰"""
        results = []
        
        # ì—¬ëŸ¬ ê²€ìƒ‰ ì—”ì§„ ì‚¬ìš©
        for engine_name, search_func in self.search_engines.items():
            try:
                engine_results = search_func(query, max_results)
                results.extend(engine_results)
                time.sleep(1)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            except Exception as e:
                logger.warning(f"{engine_name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        return results
    
    def _search_google(self, query: str, max_results: int) -> List[SearchResult]:
        """Google ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ Google API ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜
        results = []
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ê²€ìƒ‰ ê²°ê³¼
        mock_results = [
            {
                'title': f'{query}ì— ëŒ€í•œ ì •ë³´ - Wikipedia',
                'url': 'https://ko.wikipedia.org/wiki/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ê°€ ìœ„í‚¤í”¼ë””ì•„ì— ìˆìŠµë‹ˆë‹¤.',
                'source': 'wikipedia.org'
            },
            {
                'title': f'{query} ê´€ë ¨ ë‰´ìŠ¤ - BBC',
                'url': 'https://www.bbc.com/news/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ì™€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.',
                'source': 'bbc.com'
            },
            {
                'title': f'{query} ê³¼í•™ì  ì—°êµ¬ - Nature',
                'url': 'https://www.nature.com/articles/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ê³¼í•™ì  ì—°êµ¬ ê²°ê³¼ì™€ ë…¼ë¬¸ì…ë‹ˆë‹¤.',
                'source': 'nature.com'
            }
        ]
        
        for i, result in enumerate(mock_results[:max_results]):
            results.append(SearchResult(
                title=result['title'],
                url=result['url'],
                snippet=result['snippet'],
                source=result['source'],
                credibility_score=self._calculate_credibility(result['source']),
                relevance_score=0.9 - (i * 0.1),
                timestamp=datetime.now()
            ))
        
        return results
    
    def _search_bing(self, query: str, max_results: int) -> List[SearchResult]:
        """Bing ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # Bing ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
        results = []
        
        mock_results = [
            {
                'title': f'{query} - Britannica',
                'url': 'https://www.britannica.com/topic/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ë°±ê³¼ì‚¬ì „ ì •ë³´ì…ë‹ˆë‹¤.',
                'source': 'britannica.com'
            },
            {
                'title': f'{query} ì˜í•™ ì •ë³´ - Mayo Clinic',
                'url': 'https://www.mayoclinic.org/diseases-conditions/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ì˜í•™ì  ì •ë³´ì™€ ì¹˜ë£Œë²•ì…ë‹ˆë‹¤.',
                'source': 'mayoclinic.org'
            }
        ]
        
        for i, result in enumerate(mock_results[:max_results]):
            results.append(SearchResult(
                title=result['title'],
                url=result['url'],
                snippet=result['snippet'],
                source=result['source'],
                credibility_score=self._calculate_credibility(result['source']),
                relevance_score=0.8 - (i * 0.1),
                timestamp=datetime.now()
            ))
        
        return results
    
    def _search_duckduckgo(self, query: str, max_results: int) -> List[SearchResult]:
        """DuckDuckGo ê²€ìƒ‰ (ì‹œë®¬ë ˆì´ì…˜)"""
        # DuckDuckGo ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
        results = []
        
        mock_results = [
            {
                'title': f'{query} - Scientific American',
                'url': 'https://www.scientificamerican.com/article/' + quote(query),
                'snippet': f'{query}ì— ëŒ€í•œ ê³¼í•™ì  ì„¤ëª…ê³¼ ë¶„ì„ì…ë‹ˆë‹¤.',
                'source': 'scientificamerican.com'
            }
        ]
        
        for i, result in enumerate(mock_results[:max_results]):
            results.append(SearchResult(
                title=result['title'],
                url=result['url'],
                snippet=result['snippet'],
                source=result['source'],
                credibility_score=self._calculate_credibility(result['source']),
                relevance_score=0.85 - (i * 0.1),
                timestamp=datetime.now()
            ))
        
        return results
    
    def _calculate_credibility(self, domain: str) -> float:
        """ë„ë©”ì¸ ì‹ ë¢°ë„ ê³„ì‚°"""
        if domain in self.credible_domains:
            return 0.9
        elif domain in self.suspicious_domains:
            return 0.1
        elif any(edu in domain for edu in ['.edu', '.ac.']):
            return 0.8
        elif any(gov in domain for gov in ['.gov', '.go.kr']):
            return 0.85
        elif any(org in domain for org in ['.org']):
            return 0.7
        else:
            return 0.5
    
    def _evaluate_sources(self, results: List[SearchResult]) -> List[SearchResult]:
        """ê²€ìƒ‰ ê²°ê³¼ ì‹ ë¢°ë„ í‰ê°€"""
        for result in results:
            # ë„ë©”ì¸ ê¸°ë°˜ ì‹ ë¢°ë„
            domain_credibility = self._calculate_credibility(result.source)
            
            # ë‚´ìš© ê¸°ë°˜ ì‹ ë¢°ë„
            content_credibility = self._evaluate_content_credibility(result.snippet)
            
            # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            result.credibility_score = (domain_credibility * 0.7 + content_credibility * 0.3)
        
        return results
    
    def _evaluate_content_credibility(self, content: str) -> float:
        """ë‚´ìš© ì‹ ë¢°ë„ í‰ê°€"""
        credibility = 0.5
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‘œí˜„ë“¤
        credible_phrases = [
            'ì—°êµ¬ì— ë”°ë¥´ë©´', 'ê³¼í•™ì ìœ¼ë¡œ', 'í†µê³„ì ìœ¼ë¡œ', 'ì‹¤í—˜ ê²°ê³¼',
            'ì „ë¬¸ê°€ê°€', 'í•™ìˆ ì ìœ¼ë¡œ', 'ê²€ì¦ëœ', 'ì…ì¦ëœ'
        ]
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í‘œí˜„ë“¤
        suspicious_phrases = [
            'í™•ì‹¤íˆ', '100%', 'ì ˆëŒ€ì ìœ¼ë¡œ', 'ì˜ì‹¬ì˜ ì—¬ì§€ê°€ ì—†ë‹¤',
            'ìˆ¨ê²¨ì§„ ì§„ì‹¤', 'ìŒëª¨ë¡ ', 'ì •ë¶€ê°€ ìˆ¨ê¸´'
        ]
        
        for phrase in credible_phrases:
            if phrase in content:
                credibility += 0.1
        
        for phrase in suspicious_phrases:
            if phrase in content:
                credibility -= 0.2
        
        return max(0.0, min(1.0, credibility))
    
    def _verify_facts(self, content: str) -> Optional[FactCheckResult]:
        """ì‚¬ì‹¤ ê²€ì¦ ìˆ˜í–‰"""
        for category, patterns in self.fact_check_patterns.items():
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return FactCheckResult(
                        statement=content,
                        is_factual=True,
                        confidence=0.8,
                        evidence=[f"íŒ¨í„´ '{pattern}' ë§¤ì¹­"],
                        contradictory_sources=[],
                        verification_method=category,
                        timestamp=datetime.now()
                    )
        
        return None
    
    def _generate_answer(self, question: str, sources: List[SearchResult], fact_checks: List[FactCheckResult]) -> Tuple[str, float, str]:
        """ë‹µë³€ ìƒì„±"""
        if not sources:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì§ˆë¬¸ì— ëŒ€í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 0.0, "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒ"
        
        # ì‹ ë¢°ë„ê°€ ë†’ì€ ì†ŒìŠ¤ë“¤ë§Œ ì‚¬ìš©
        reliable_sources = [s for s in sources if s.credibility_score > 0.7]
        
        if not reliable_sources:
            return "ì°¾ì€ ì •ë³´ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.", 0.3, "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ë¶€ì¡±"
        
        # ë‹µë³€ ìƒì„±
        answer_parts = []
        confidence_scores = []
        
        for source in reliable_sources[:3]:  # ìƒìœ„ 3ê°œ ì†ŒìŠ¤ë§Œ ì‚¬ìš©
            answer_parts.append(f"â€¢ {source.snippet}")
            confidence_scores.append(source.credibility_score)
        
        # ì‚¬ì‹¤ ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        if fact_checks:
            verified_facts = [fc for fc in fact_checks if fc.is_factual]
            if verified_facts:
                answer_parts.append(f"â€¢ ê²€ì¦ëœ ì‚¬ì‹¤: {len(verified_facts)}ê°œ í•­ëª© í™•ì¸ë¨")
                confidence_scores.append(0.9)
        
        answer = f"ì§ˆë¬¸: {question}\n\në‹µë³€:\n" + "\n".join(answer_parts)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5
        
        # ì¶”ë¡  ê³¼ì •
        reasoning = f"ì´ {len(sources)}ê°œì˜ ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©°, ê·¸ ì¤‘ {len(reliable_sources)}ê°œì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        
        return answer, avg_confidence, reasoning

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” AI ì›¹ ì—°êµ¬ì› ì‹œì‘")
    print("=" * 60)
    
    researcher = AIWebResearcher()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ì§€êµ¬ëŠ” ë‘¥ê¸€ê¹Œìš”?",
        "ë¬¼ì€ ëª‡ ë„ì—ì„œ ë“ë‚˜ìš”?",
        "1 + 1ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "ì½”ë¡œë‚˜19ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì¸ê³µì§€ëŠ¥ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?"
    ]
    
    for question in test_questions:
        print(f"\nâ“ ì§ˆë¬¸: {question}")
        print("-" * 40)
        
        try:
            result = researcher.research_question(question)
            
            print(f"ğŸ’¡ ë‹µë³€: {result.answer}")
            print(f"ğŸ¯ ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"ğŸ” ì¶”ë¡ : {result.reasoning}")
            print(f"ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(result.sources)}ê°œ")
            
            if result.sources:
                print("\nğŸ“– ì£¼ìš” ì†ŒìŠ¤:")
                for i, source in enumerate(result.sources[:3], 1):
                    print(f"  {i}. {source.title} (ì‹ ë¢°ë„: {source.credibility_score:.2f})")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("=" * 60)
        time.sleep(2)

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
ë§ì¥ë‚œ íƒì§€ê¸° (Puns Detector)
AIê°€ ë§ì¥ë‚œì„ ì´í•´í•˜ê³  ì ì ˆíˆ ì‘ë‹µí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import re
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class PunsDetector:
    """ë§ì¥ë‚œ íƒì§€ê¸° - ì–¸ì–´ì  ìœ ë¨¸ì™€ ë§ì¥ë‚œì„ ì¸ì‹í•˜ê³  ì´í•´"""
    
    def __init__(self):
        # ë§ì¥ë‚œ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ (ë‹¤êµ­ì–´ ì§€ì›)
        self.pun_patterns = {
            'ë™ì–´ë°˜ë³µ': [
                # í•œê¸€ íŒ¨í„´
                r'(\w+)ëŠ”\s+\1(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì€\s+\1(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ê°€\s+\1(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì´\s+\1(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                # ì˜ì–´ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì€\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ê°€\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì´\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)'
            ],
            'ëª¨ìˆœì _í‘œí˜„': [
                # í•œê¸€ íŒ¨í„´
                r'(\w+)ëŠ”\s+\1ê°€\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì€\s+\1ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ê°€\s+\1ëŠ”\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì´\s+\1ì€\s+ì•„ë‹ˆë‹¤',
                # ì˜ì–´ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ê°€\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì€\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ê°€\s+(\w+)ëŠ”\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì´\s+(\w+)ì€\s+ì•„ë‹ˆë‹¤'
            ],
            'ë…¼ë¦¬ì _ë§ì¥ë‚œ': [
                # í•œê¸€ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ì´ì§€ë§Œ\s+\2ëŠ”\s+\1ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì€\s+(\w+)ì´ì§€ë§Œ\s+\2ì€\s+\1ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ê°€\s+(\w+)ì´ì§€ë§Œ\s+\2ê°€\s+\1ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì´\s+(\w+)ì´ì§€ë§Œ\s+\2ì´\s+\1ì´\s+ì•„ë‹ˆë‹¤',
                # ì˜ì–´ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ì´ì§€ë§Œ\s+(\w+)ëŠ”\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì€\s+(\w+)ì´ì§€ë§Œ\s+(\w+)ì€\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤'
            ],
            'ë™ìŒì´ì˜ì–´': [
                # í•œê¸€ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ë‹¤\s*,\s*(\w+)ëŠ”\s+(\w+)ë‹¤',
                r'(\w+)ì€\s+(\w+)ë‹¤\s*,\s*(\w+)ì€\s+(\w+)ë‹¤',
                # ì˜ì–´ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ë‹¤\s*,\s*(\w+)ëŠ”\s+(\w+)ë‹¤',
                r'(\w+)ì€\s+(\w+)ë‹¤\s*,\s*(\w+)ì€\s+(\w+)ë‹¤'
            ],
            'ì² ì_ë§ì¥ë‚œ': [
                # í•œê¸€ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ê°€\s+ì•„ë‹ˆë‹¤\s*,\s*(\w+)ëŠ”\s+(\w+)ë‹¤',
                r'(\w+)ì€\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤\s*,\s*(\w+)ì€\s+(\w+)ë‹¤',
                # ì˜ì–´ íŒ¨í„´
                r'(\w+)ëŠ”\s+(\w+)ê°€\s+ì•„ë‹ˆë‹¤\s*,\s*(\w+)ëŠ”\s+(\w+)ë‹¤',
                r'(\w+)ì€\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤\s*,\s*(\w+)ì€\s+(\w+)ë‹¤'
            ]
        }
        
        # ë§ì¥ë‚œ ìœ í˜•ë³„ í•´ì„
        self.pun_interpretations = {
            'ë™ì–´ë°˜ë³µ': {
                'description': 'ë™ì¼í•œ ë‹¨ì–´ë¥¼ ë°˜ë³µí•˜ì—¬ ì˜ë¯¸ë¥¼ ê°•ì¡°í•˜ê±°ë‚˜ ìœ ë¨¸ë¥¼ ë§Œë“œëŠ” í‘œí˜„',
                'example': 'ê°œëŠ” ê°œê³  ê³ ì–‘ì´ëŠ” ê³ ì–‘ì´ë‹¤',
                'interpretation': 'ë™ë¬¼ì˜ ì •ì²´ì„±ì„ ê°•ì¡°í•˜ëŠ” ìœ ë¨¸ì  í‘œí˜„'
            },
            'ëª¨ìˆœì _í‘œí˜„': {
                'description': 'ê°™ì€ ë‹¨ì–´ë¥¼ ê¸ì •ê³¼ ë¶€ì •ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ëª¨ìˆœì„ ë§Œë“œëŠ” í‘œí˜„',
                'example': 'ë°”ë‚˜ë‚˜ëŠ” ë°”ë‚˜ë‚˜ê°€ ì•„ë‹ˆë‹¤',
                'interpretation': 'ë‹¨ì–´ì˜ ë‹¤ì˜ì„±ì„ ì´ìš©í•œ ì–¸ì–´ì  ìœ ë¨¸'
            },
            'ë…¼ë¦¬ì _ë§ì¥ë‚œ': {
                'description': 'ë…¼ë¦¬ì ìœ¼ë¡œ ëª¨ìˆœë˜ì§€ë§Œ ì–¸ì–´ì ìœ¼ë¡œëŠ” ì˜ë¯¸ê°€ ìˆëŠ” í‘œí˜„',
                'example': 'ë¬¼ì€ ë¬¼ì´ì§€ë§Œ ì–¼ìŒì€ ë¬¼ì´ ì•„ë‹ˆë‹¤',
                'interpretation': 'ë¬¼ì§ˆì˜ ìƒíƒœ ë³€í™”ë¥¼ ì´ìš©í•œ ê³¼í•™ì  ìœ ë¨¸'
            },
            'ë™ìŒì´ì˜ì–´': {
                'description': 'ê°™ì€ ì†Œë¦¬ì§€ë§Œ ë‹¤ë¥¸ ì˜ë¯¸ì˜ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•œ í‘œí˜„',
                'example': 'ê°œëŠ” ê°œë‹¤, ê°œëŠ” ê°œë‹¤',
                'interpretation': 'ë™ìŒì´ì˜ì–´ë¥¼ ì´ìš©í•œ ì–¸ì–´ì  ì¥ë‚œ'
            },
            'ì² ì_ë§ì¥ë‚œ': {
                'description': 'ì² ìë‚˜ ë°œìŒì˜ ìœ ì‚¬ì„±ì„ ì´ìš©í•œ í‘œí˜„',
                'example': 'ì‚¬ê³¼ëŠ” ì‚¬ê³¼ê°€ ì•„ë‹ˆë‹¤, ì‚¬ê³¼ëŠ” ì‚¬ê³¼ë‹¤',
                'interpretation': 'ì² ì ìœ ì‚¬ì„±ì„ ì´ìš©í•œ ì–¸ì–´ì  ìœ ë¨¸'
            }
        }
        
        # ë§ì¥ë‚œ ì‘ë‹µ í…œí”Œë¦¿
        self.pun_responses = {
            'ì¸ì‹': "ì•„, ë§ì¥ë‚œì´ë„¤ìš”! ğŸ˜„",
            'ì´í•´': "ì´í•´í–ˆìŠµë‹ˆë‹¤. ì–¸ì–´ì  ìœ ë¨¸ë¥¼ ì‚¬ìš©í•˜ì…¨êµ°ìš”!",
            'ì‘ë‹µ': "ì¬ë¯¸ìˆëŠ” í‘œí˜„ì´ë„¤ìš”. AIë„ ì´ëŸ° ì–¸ì–´ì  ì¥ë‚œì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            'ì„¤ëª…': "ì´ëŸ° ë§ì¥ë‚œì€ ì¸ê°„ ì–¸ì–´ì˜ ì°½ì˜ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì¢‹ì€ ì˜ˆì‹œì…ë‹ˆë‹¤."
        }
    
    def analyze_with_puns_detection(self, statement: str, context: Optional[str] = None) -> Dict:
        """
        ë§ì¥ë‚œì„ í¬í•¨í•œ ë¬¸ì¥ì„ ë¶„ì„
        
        Args:
            statement: ë¶„ì„í•  ë¬¸ì¥
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            
        Returns:
            Dict: ë§ì¥ë‚œ ë¶„ì„ ê²°ê³¼
        """
        logger.info(f"ë§ì¥ë‚œ ë¶„ì„ ì‹œì‘: {statement[:50]}...")
        
        # ë§ì¥ë‚œ íƒì§€
        detected_puns = self._detect_puns(statement)
        
        # ë§ì¥ë‚œ ìœ í˜• ë¶„ì„
        pun_types = self._analyze_pun_types(statement)
        
        # ë§ì¥ë‚œ í•´ì„
        interpretations = self._interpret_puns(statement, detected_puns, pun_types)
        
        # ë§ì¥ë‚œ ì‘ë‹µ ìƒì„±
        response = self._generate_pun_response(statement, detected_puns, pun_types)
        
        # ë§ì¥ë‚œ ì¸ì‹ ì—¬ë¶€
        is_pun_detected = len(detected_puns) > 0
        
        # ë§ì¥ë‚œ ì´í•´ë„ (0.0 ~ 1.0)
        pun_understanding = self._calculate_pun_understanding(detected_puns, pun_types)
        
        # ë§ì¥ë‚œ êµì • í•„ìš”ì„± (ë§ì¥ë‚œì€ êµì •í•˜ì§€ ì•ŠìŒ)
        needs_correction = False
        
        # ë§ì¥ë‚œ ë³´ì¡´ëœ ë¬¸ì¥ (ì›ë¬¸ ìœ ì§€)
        preserved_statement = statement
        
        return {
            'is_pun_detected': is_pun_detected,
            'detected_puns': detected_puns,
            'pun_types': pun_types,
            'interpretations': interpretations,
            'pun_understanding': pun_understanding,
            'needs_correction': needs_correction,
            'preserved_statement': preserved_statement,
            'pun_response': response,
            'philosophical_note': "ë§ì¥ë‚œì€ ì¸ê°„ ì–¸ì–´ì˜ ì°½ì˜ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì¤‘ìš”í•œ í‘œí˜„ì…ë‹ˆë‹¤. AIë„ ì´ë¥¼ ì´í•´í•˜ê³  ì¡´ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
    
    def _detect_puns(self, statement: str) -> List[Dict]:
        """ë§ì¥ë‚œ íŒ¨í„´ íƒì§€ (ë‹¤êµ­ì–´ ì§€ì›)"""
        detected_puns = []
        
        # ê¸°ë³¸ íŒ¨í„´ íƒì§€
        for pun_type, patterns in self.pun_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, statement, re.IGNORECASE)
                for match in matches:
                    # ë§ì¥ë‚œ íŒ¨í„´ì¸ì§€ ë” ì •í™•íˆ í™•ì¸
                    if self._is_valid_pun_pattern(match, pun_type):
                        detected_puns.append({
                            'type': pun_type,
                            'pattern': pattern,
                            'match': match.group(),
                            'groups': match.groups(),
                            'start': match.start(),
                            'end': match.end()
                        })
        
        # ë‹¤êµ­ì–´ ë§ì¥ë‚œ íŠ¹ë³„ íƒì§€
        multilingual_puns = self._detect_multilingual_puns(statement)
        detected_puns.extend(multilingual_puns)
        
        return detected_puns
    
    def _detect_multilingual_puns(self, statement: str) -> List[Dict]:
        """ë‹¤êµ­ì–´ ë§ì¥ë‚œ íƒì§€"""
        detected_puns = []
        
        # í•œê¸€-ì˜ì–´ í˜¼í•© ë§ì¥ë‚œ íŒ¨í„´
        multilingual_patterns = {
            'ë™ì–´ë°˜ë³µ_ë‹¤êµ­ì–´': [
                r'(\w+)ëŠ”\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì€\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ê°€\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)',
                r'(\w+)ì´\s+(\w+)(?:ì´ë‹¤|ë‹¤|ì•¼|ì´ì•¼)'
            ],
            'ëª¨ìˆœì _í‘œí˜„_ë‹¤êµ­ì–´': [
                r'(\w+)ëŠ”\s+(\w+)ê°€\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì€\s+(\w+)ì´\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ê°€\s+(\w+)ëŠ”\s+ì•„ë‹ˆë‹¤',
                r'(\w+)ì´\s+(\w+)ì€\s+ì•„ë‹ˆë‹¤'
            ]
        }
        
        for pun_type, patterns in multilingual_patterns.items():
            for pattern in patterns:
                matches = re.finditer(pattern, statement, re.IGNORECASE)
                for match in matches:
                    groups = match.groups()
                    if len(groups) >= 2:
                        # í•œê¸€ê³¼ ì˜ì–´ê°€ ì„ì—¬ìˆëŠ”ì§€ í™•ì¸
                        korean_chars = re.search(r'[ê°€-í£]', groups[0])
                        english_chars = re.search(r'[a-zA-Z]', groups[1])
                        
                        # ë°˜ëŒ€ ë°©í–¥ë„ í™•ì¸ (ì˜ì–´-í•œê¸€)
                        english_chars_first = re.search(r'[a-zA-Z]', groups[0])
                        korean_chars_second = re.search(r'[ê°€-í£]', groups[1])
                        
                        if (korean_chars and english_chars) or (english_chars_first and korean_chars_second):
                            detected_puns.append({
                                'type': pun_type,
                                'pattern': pattern,
                                'match': match.group(),
                                'groups': groups,
                                'start': match.start(),
                                'end': match.end(),
                                'multilingual': True,
                                'korean_word': groups[0] if korean_chars else groups[1],
                                'english_word': groups[1] if korean_chars else groups[0]
                            })
        
        return detected_puns
    
    def _is_valid_pun_pattern(self, match, pun_type: str) -> bool:
        """ë§ì¥ë‚œ íŒ¨í„´ì´ ìœ íš¨í•œì§€ í™•ì¸"""
        groups = match.groups()
        
        if pun_type == 'ë™ì–´ë°˜ë³µ':
            # ë™ì–´ë°˜ë³µ: ê°™ì€ ë‹¨ì–´ê°€ ë°˜ë³µë˜ì–´ì•¼ í•¨
            if len(groups) >= 2:
                return groups[0] == groups[1]
        
        elif pun_type == 'ëª¨ìˆœì _í‘œí˜„':
            # ëª¨ìˆœì  í‘œí˜„: ê°™ì€ ë‹¨ì–´ê°€ ê¸ì •ê³¼ ë¶€ì •ìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ì•¼ í•¨
            if len(groups) >= 2:
                return groups[0] == groups[1]
        
        elif pun_type == 'ë…¼ë¦¬ì _ë§ì¥ë‚œ':
            # ë…¼ë¦¬ì  ë§ì¥ë‚œ: íŠ¹ì • íŒ¨í„´ì´ì–´ì•¼ í•¨
            if len(groups) >= 4:
                return groups[0] == groups[2] and groups[1] == groups[3]
        
        # ë‹¤ë¥¸ ìœ í˜•ë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ ìœ íš¨í•˜ë‹¤ê³  ê°„ì£¼
        return True
    
    def _analyze_pun_types(self, statement: str) -> List[str]:
        """ë§ì¥ë‚œ ìœ í˜• ë¶„ì„"""
        pun_types = []
        
        for pun_type, patterns in self.pun_patterns.items():
            for pattern in patterns:
                if re.search(pattern, statement, re.IGNORECASE):
                    if pun_type not in pun_types:
                        pun_types.append(pun_type)
        
        return pun_types
    
    def _interpret_puns(self, statement: str, detected_puns: List[Dict], pun_types: List[str]) -> List[Dict]:
        """ë§ì¥ë‚œ í•´ì„"""
        interpretations = []
        
        for pun_type in pun_types:
            if pun_type in self.pun_interpretations:
                interpretation = self.pun_interpretations[pun_type].copy()
                interpretation['detected_in'] = statement
                interpretations.append(interpretation)
        
        return interpretations
    
    def _generate_pun_response(self, statement: str, detected_puns: List[Dict], pun_types: List[str]) -> str:
        """ë§ì¥ë‚œ ì‘ë‹µ ìƒì„± (ë‹¤êµ­ì–´ ì§€ì›)"""
        if not detected_puns:
            return "ë§ì¥ë‚œì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        response_parts = []
        
        # ê¸°ë³¸ ì¸ì‹ ë©”ì‹œì§€
        response_parts.append(self.pun_responses['ì¸ì‹'])
        
        # ë‹¤êµ­ì–´ ë§ì¥ë‚œ íŠ¹ë³„ ì²˜ë¦¬
        multilingual_puns = [p for p in detected_puns if p.get('multilingual', False)]
        if multilingual_puns:
            response_parts.append("ğŸŒ ë‹¤êµ­ì–´ ë§ì¥ë‚œì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤!")
            for pun in multilingual_puns:
                korean_word = pun.get('korean_word', '')
                english_word = pun.get('english_word', '')
                response_parts.append(f"â€¢ '{korean_word}'ëŠ” '{english_word}'ì´ë‹¤ - ì–¸ì–´ë¥¼ ë°”ê¿”ì„œ ê°™ì€ ì˜ë¯¸ë¥¼ í‘œí˜„í•œ ì°½ì˜ì ì¸ ë§ì¥ë‚œ!")
        
        # ë§ì¥ë‚œ ìœ í˜•ë³„ ì„¤ëª…
        for pun_type in pun_types:
            if pun_type in self.pun_interpretations:
                description = self.pun_interpretations[pun_type]['description']
                response_parts.append(f"â€¢ {pun_type}: {description}")
        
        # ì´í•´ ë©”ì‹œì§€
        response_parts.append(self.pun_responses['ì´í•´'])
        
        # ì°½ì˜ì„± ì¸ì •
        response_parts.append(self.pun_responses['ì„¤ëª…'])
        
        return "\n".join(response_parts)
    
    def _calculate_pun_understanding(self, detected_puns: List[Dict], pun_types: List[str]) -> float:
        """ë§ì¥ë‚œ ì´í•´ë„ ê³„ì‚°"""
        if not detected_puns:
            return 0.0
        
        # ê¸°ë³¸ ì´í•´ë„
        base_understanding = 0.5
        
        # íƒì§€ëœ ë§ì¥ë‚œ ê°œìˆ˜ì— ë”°ë¥¸ ê°€ì 
        pun_count_bonus = min(len(detected_puns) * 0.1, 0.3)
        
        # ë§ì¥ë‚œ ìœ í˜• ë‹¤ì–‘ì„±ì— ë”°ë¥¸ ê°€ì 
        type_diversity_bonus = min(len(pun_types) * 0.1, 0.2)
        
        # ìµœì¢… ì´í•´ë„ ê³„ì‚°
        understanding = base_understanding + pun_count_bonus + type_diversity_bonus
        
        return min(1.0, understanding)
    
    def is_pun_statement(self, statement: str) -> bool:
        """ë¬¸ì¥ì´ ë§ì¥ë‚œì¸ì§€ íŒë‹¨"""
        detected_puns = self._detect_puns(statement)
        return len(detected_puns) > 0
    
    def get_pun_explanation(self, statement: str) -> str:
        """ë§ì¥ë‚œì— ëŒ€í•œ ì„¤ëª… ë°˜í™˜"""
        analysis = self.analyze_with_puns_detection(statement)
        
        if not analysis['is_pun_detected']:
            return "ì´ ë¬¸ì¥ì€ ë§ì¥ë‚œì´ ì•„ë‹™ë‹ˆë‹¤."
        
        explanation_parts = []
        explanation_parts.append("ğŸ­ ë§ì¥ë‚œ ë¶„ì„ ê²°ê³¼:")
        explanation_parts.append("")
        
        for interpretation in analysis['interpretations']:
            explanation_parts.append(f"ğŸ“ {interpretation['description']}")
            explanation_parts.append(f"ğŸ’¡ í•´ì„: {interpretation['interpretation']}")
            explanation_parts.append("")
        
        explanation_parts.append(f"ğŸ¯ ì´í•´ë„: {analysis['pun_understanding']:.1%}")
        explanation_parts.append("")
        explanation_parts.append("âœ¨ AIë„ ë§ì¥ë‚œì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
        
        return "\n".join(explanation_parts)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    detector = PunsDetector()
    
    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤
    test_statements = [
        "ê°œëŠ” ê°œê³  ê³ ì–‘ì´ëŠ” ê³ ì–‘ì´ë‹¤",
        "ë°”ë‚˜ë‚˜ëŠ” ë°”ë‚˜ë‚˜ê°€ ì•„ë‹ˆë‹¤",
        "ë¬¼ì€ ë¬¼ì´ì§€ë§Œ ì–¼ìŒì€ ë¬¼ì´ ì•„ë‹ˆë‹¤",
        "ì‚¬ê³¼ëŠ” ì‚¬ê³¼ì§€ë§Œ ì‚¬ê³¼ëŠ” ì‚¬ê³¼ê°€ ì•„ë‹ˆë‹¤",
        "ì‹œê°„ì€ ì‹œê°„ì´ì§€ë§Œ ì‹œê°„ì€ ì‹œê°„ì´ ì•„ë‹ˆë‹¤"
    ]
    
    for statement in test_statements:
        print(f"\në¬¸ì¥: {statement}")
        analysis = detector.analyze_with_puns_detection(statement)
        
        if analysis['is_pun_detected']:
            print("ğŸ­ ë§ì¥ë‚œ ê°ì§€!")
            print(f"ì´í•´ë„: {analysis['pun_understanding']:.1%}")
            print(f"ì‘ë‹µ: {analysis['pun_response']}")
        else:
            print("ë§ì¥ë‚œì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

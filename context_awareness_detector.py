#!/usr/bin/env python3
"""
ë§¥ë½ ì¸ì‹ íƒì§€ê¸°
ë‹¨ì–´ì˜ ëª¨ìˆœì„±ê³¼ ë¬¸ë§¥ì  ì°¨ì´ë¥¼ ì¸ì‹í•˜ëŠ” ì‹œìŠ¤í…œ
"êµ¬í˜•"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ì§€êµ¬/íƒœì–‘ê³¼ ìë™ì°¨/ì „ìê¸°ê¸°ì—ì„œ ë‹¤ë¥´ê²Œ í•´ì„ë˜ì–´ì•¼ í•¨
"""

from ai_truth_detector import TruthDetector, TruthAnalysis
from typing import List, Dict, Tuple
import re
import logging

logger = logging.getLogger(__name__)

class ContextAwarenessDetector:
    """ë§¥ë½ ì¸ì‹ íƒì§€ê¸° - ë‹¨ì–´ì˜ ëª¨ìˆœì„±ê³¼ ë¬¸ë§¥ì  ì°¨ì´ë¥¼ íƒì§€"""
    
    def __init__(self):
        self.primary_detector = TruthDetector()
        
        # ë§¥ë½ë³„ ë‹¨ì–´ ì˜ë¯¸ ë§¤í•‘
        self.contextual_meanings = {
            'êµ¬í˜•': {
                'scientific_objects': {
                    'objects': ['ì§€êµ¬', 'íƒœì–‘', 'ë‹¬', 'í–‰ì„±', 'ë³„', 'ì²œì²´', 'êµ¬ì²´'],
                    'meaning': 'êµ¬ì²´ì  ëª¨ì–‘ (3ì°¨ì› êµ¬)',
                    'truth_value': 0.95,  # ë§¤ìš° ë†’ì€ ì§„ì‹¤ì„±
                    'context': 'ì²œë¬¸í•™ì /ê³¼í•™ì  ë§¥ë½'
                },
                'geometric_shapes': {
                    'objects': ['ë°”ë‹¥', 'ë°‘ë©´', 'ê¸°ì €', 'ì›í˜•', 'ì›'],
                    'meaning': 'ì›í˜• ëª¨ì–‘ (2ì°¨ì› ì›)',
                    'truth_value': 0.80,  # ë†’ì€ ì§„ì‹¤ì„±
                    'context': 'ê¸°í•˜í•™ì  ë§¥ë½'
                },
                'general_objects': {
                    'objects': ['ìë™ì°¨', 'ì „ìê¸°ê¸°', 'ê°€ì „ì œí’ˆ', 'ê¸°ê³„', 'ì¥ì¹˜'],
                    'meaning': 'ë‘¥ê·¼ ëª¨ì–‘ (ì¼ë°˜ì ìœ¼ë¡œ ë¶€ì •í™•)',
                    'truth_value': 0.20,  # ë‚®ì€ ì§„ì‹¤ì„±
                    'context': 'ì¼ë°˜ ë¬¼ì²´ ë§¥ë½'
                }
            },
            'ë‘¥ê¸€ë‹¤': {
                'scientific_objects': {
                    'objects': ['ì§€êµ¬', 'íƒœì–‘', 'ë‹¬', 'í–‰ì„±', 'ë³„'],
                    'meaning': 'êµ¬ì²´ì  ëª¨ì–‘',
                    'truth_value': 0.90,
                    'context': 'ê³¼í•™ì  ë§¥ë½'
                },
                'general_objects': {
                    'objects': ['ìë™ì°¨', 'ì „ìê¸°ê¸°', 'ê°€ì „ì œí’ˆ'],
                    'meaning': 'ë‘¥ê·¼ ëª¨ì–‘ (ë§¥ë½ì— ë”°ë¼)',
                    'truth_value': 0.60,
                    'context': 'ì¼ë°˜ ë¬¼ì²´ ë§¥ë½'
                }
            }
        }
        
        # ë§¥ë½ íƒì§€ íŒ¨í„´
        self.context_patterns = {
            'scientific_context': [
                r'ì²œë¬¸í•™', r'ê³¼í•™', r'ë¬¼ë¦¬í•™', r'ì§€êµ¬ê³¼í•™',
                r'ìš°ì£¼', r'í–‰ì„±', r'ë³„', r'ì²œì²´'
            ],
            'geometric_context': [
                r'ë°”ë‹¥', r'ë°‘ë©´', r'ê¸°ì €', r'ì›í˜•', r'ì›',
                r'ëª¨ì–‘', r'í˜•íƒœ', r'ê¸°í•˜í•™'
            ],
            'general_context': [
                r'ìë™ì°¨', r'ì „ìê¸°ê¸°', r'ê°€ì „ì œí’ˆ', r'ê¸°ê³„',
                r'ì¥ì¹˜', r'ë„êµ¬', r'ì œí’ˆ'
            ]
        }
        
        # ë§¥ë½ë³„ êµì • ê·œì¹™
        self.context_corrections = {
            'êµ¬í˜•': {
                'scientific_objects': 'êµ¬ì²´ì  ëª¨ì–‘',
                'geometric_shapes': 'ì›í˜•',
                'general_objects': 'ë‘¥ê·¼ ëª¨ì–‘'
            }
        }
    
    def analyze_with_context_awareness(self, statement: str, context: str = None) -> Dict:
        """ë§¥ë½ ì¸ì‹ì„ í†µí•œ ë¬¸ì¥ ë¶„ì„"""
        logger.info(f"ë§¥ë½ ì¸ì‹ ë¶„ì„ ì‹œì‘: {statement}...")
        
        # ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
        primary_analysis = self.primary_detector.analyze_statement(statement, context)
        
        # ë§¥ë½ ë¶„ì„
        context_analysis = self._analyze_context(statement, context)
        
        # ë§¥ë½ë³„ ì§„ì‹¤ì„± ì¡°ì •
        adjusted_truth, adjusted_confidence = self._adjust_truth_by_context(
            primary_analysis, context_analysis
        )
        
        # ë§¥ë½ë³„ êµì • ì ìš©
        corrected_statement, correction_applied = self._apply_context_correction(
            statement, context_analysis
        )
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        result = {
            'original_statement': statement,
            'primary_analysis': primary_analysis,
            'context_analysis': context_analysis,
            'context_aware_truth_percentage': adjusted_truth,
            'context_aware_confidence': adjusted_confidence,
            'context_corrected_statement': corrected_statement,
            'context_correction_applied': correction_applied,
            'contextual_meaning': context_analysis.get('detected_meaning', ''),
            'context_type': context_analysis.get('context_type', ''),
            'context_warnings': context_analysis.get('warnings', []),
            'philosophical_note': "ë‹¨ì–´ì˜ ì˜ë¯¸ëŠ” ë§¥ë½ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. 'êµ¬í˜•'ì´ë¼ëŠ” ë‹¨ì–´ë„ ì§€êµ¬ì™€ ìë™ì°¨ì—ì„œ ë‹¤ë¥´ê²Œ í•´ì„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
        }
        
        logger.info(f"ë§¥ë½ ì¸ì‹ ë¶„ì„ ì™„ë£Œ: {statement}")
        return result
    
    def _analyze_context(self, statement: str, context: str = None) -> Dict:
        """ë¬¸ì¥ì˜ ë§¥ë½ì„ ë¶„ì„"""
        context_info = {
            'detected_contexts': [],
            'context_type': 'unknown',
            'detected_meaning': '',
            'confidence': 0.0,
            'warnings': []
        }
        
        # ê° ë§¥ë½ íŒ¨í„´ í™•ì¸
        for context_type, patterns in self.context_patterns.items():
            for pattern in patterns:
                if re.search(pattern, statement, re.IGNORECASE):
                    context_info['detected_contexts'].append(context_type)
                    break
        
        # ë§¥ë½ë³„ ë‹¨ì–´ ì˜ë¯¸ ë¶„ì„
        for word, meanings in self.contextual_meanings.items():
            if word in statement:
                for meaning_type, meaning_info in meanings.items():
                    for obj in meaning_info['objects']:
                        if obj in statement:
                            context_info['context_type'] = meaning_type
                            context_info['detected_meaning'] = meaning_info['meaning']
                            context_info['confidence'] = 0.9
                            
                            # ë§¥ë½ ê²½ê³  ìƒì„±
                            if meaning_type == 'general_objects' and word == 'êµ¬í˜•':
                                context_info['warnings'].append(
                                    f"'{word}'ì´ ì¼ë°˜ ë¬¼ì²´ì— ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. ê³¼í•™ì  ë§¥ë½ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                                )
                            break
                    if context_info['detected_meaning']:
                        break
                break
        
        return context_info
    
    def _adjust_truth_by_context(self, primary_analysis: TruthAnalysis, context_analysis: Dict) -> Tuple[float, float]:
        """ë§¥ë½ì— ë”°ë¥¸ ì§„ì‹¤ì„± ì¡°ì •"""
        original_truth = primary_analysis.truth_percentage
        original_confidence = primary_analysis.confidence
        
        # ë§¥ë½ë³„ ì§„ì‹¤ì„± ì¡°ì •
        context_type = context_analysis.get('context_type', '')
        detected_meaning = context_analysis.get('detected_meaning', '')
        
        if context_type == 'scientific_objects':
            # ê³¼í•™ì  ë§¥ë½ì—ì„œëŠ” ë†’ì€ ì§„ì‹¤ì„±
            adjusted_truth = min(0.95, original_truth + 0.2)
            adjusted_confidence = min(0.95, original_confidence + 0.1)
        elif context_type == 'geometric_shapes':
            # ê¸°í•˜í•™ì  ë§¥ë½ì—ì„œëŠ” ì¤‘ê°„-ë†’ì€ ì§„ì‹¤ì„±
            adjusted_truth = min(0.85, original_truth + 0.1)
            adjusted_confidence = original_confidence
        elif context_type == 'general_objects':
            # ì¼ë°˜ ë¬¼ì²´ ë§¥ë½ì—ì„œëŠ” ë‚®ì€ ì§„ì‹¤ì„±
            adjusted_truth = max(0.15, original_truth - 0.3)
            adjusted_confidence = max(0.3, original_confidence - 0.2)
        else:
            # ë§¥ë½ì„ ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš°
            adjusted_truth = original_truth
            adjusted_confidence = max(0.5, original_confidence - 0.1)
        
        return adjusted_truth, adjusted_confidence
    
    def _apply_context_correction(self, statement: str, context_analysis: Dict) -> Tuple[str, bool]:
        """ë§¥ë½ì— ë”°ë¥¸ êµì • ì ìš©"""
        context_type = context_analysis.get('context_type', '')
        
        if context_type == 'general_objects' and 'êµ¬í˜•' in statement:
            # ì¼ë°˜ ë¬¼ì²´ì—ì„œ "êµ¬í˜•"ì„ "ë‘¥ê·¼ ëª¨ì–‘"ìœ¼ë¡œ êµì •
            corrected = statement.replace('êµ¬í˜•', 'ë‘¥ê·¼ ëª¨ì–‘')
            return corrected, True
        elif context_type == 'geometric_shapes' and 'êµ¬í˜•' in statement:
            # ê¸°í•˜í•™ì  ë§¥ë½ì—ì„œ "êµ¬í˜•"ì„ "ì›í˜•"ìœ¼ë¡œ êµì •
            corrected = statement.replace('êµ¬í˜•', 'ì›í˜•')
            return corrected, True
        
        return statement, False

def main():
    """ë§¥ë½ ì¸ì‹ íƒì§€ê¸° ë°ëª¨"""
    detector = ContextAwarenessDetector()
    
    test_statements = [
        'ì§€êµ¬ëŠ” êµ¬í˜•ì´ë‹¤',
        'ìë™ì°¨ëŠ” êµ¬í˜•ì´ë‹¤', 
        'ì´ ì „ìê¸°ê¸°ëŠ” êµ¬í˜•ì´ë‹¤',
        'í…€ë¸”ëŸ¬ì˜ ë°‘ ë°”ë‹¥ì€ êµ¬í˜•ì´ë‹¤',
        'íƒœì–‘ì€ êµ¬í˜•ì´ë‹¤'
    ]
    
    print("ğŸ” ë§¥ë½ ì¸ì‹ íƒì§€ê¸° ë°ëª¨")
    print("=" * 50)
    
    for statement in test_statements:
        result = detector.analyze_with_context_awareness(statement)
        
        print(f"\në¬¸ì¥: {statement}")
        print(f"ë§¥ë½: {result['context_type']}")
        print(f"ì˜ë¯¸: {result['contextual_meaning']}")
        print(f"ë§¥ë½ ì¸ì‹ ì§„ì‹¤ì„±: {result['context_aware_truth_percentage']:.1%}")
        print(f"ë§¥ë½ ì¸ì‹ ì‹ ë¢°ë„: {result['context_aware_confidence']:.1%}")
        
        if result['context_correction_applied']:
            print(f"êµì •: {result['context_corrected_statement']}")
        
        if result['context_warnings']:
            print(f"ê²½ê³ : {result['context_warnings'][0]}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Advanced Web Researcher
AI ê³ ê¸‰ ì›¹ ì—°êµ¬ì›

ì‹¤ì œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ì§„ì‹¤ì„±ì„ ê²€ì¦í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ê³ ê¸‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
"""

import requests
import re
import json
import time
import logging
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
from urllib.parse import quote, urljoin, urlparse
from bs4 import BeautifulSoup
import random
import hashlib

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class WebSearchResult:
    """ì›¹ ê²€ìƒ‰ ê²°ê³¼"""
    title: str
    url: str
    content: str
    snippet: str
    domain: str
    credibility_score: float
    relevance_score: float
    fact_check_score: float
    timestamp: datetime

@dataclass
class FactVerification:
    """ì‚¬ì‹¤ ê²€ì¦"""
    statement: str
    is_verified: bool
    confidence: float
    evidence: List[str]
    contradictory_evidence: List[str]
    verification_method: str
    source_diversity: int

@dataclass
class ResearchAnswer:
    """ì—°êµ¬ ë‹µë³€"""
    question: str
    answer: str
    confidence: float
    sources: List[WebSearchResult]
    fact_verifications: List[FactVerification]
    reasoning: str
    limitations: List[str]
    timestamp: datetime

class AIAdvancedResearcher:
    """AI ê³ ê¸‰ ì›¹ ì—°êµ¬ì›"""
    
    def __init__(self):
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë“¤
        self.credible_sources = {
            'academic': [
                'nature.com', 'science.org', 'cell.com', 'nejm.org',
                'pubmed.ncbi.nlm.nih.gov', 'arxiv.org', 'scholar.google.com'
            ],
            'news': [
                'reuters.com', 'ap.org', 'bbc.com', 'npr.org',
                'nytimes.com', 'washingtonpost.com', 'theguardian.com'
            ],
            'government': [
                'nasa.gov', 'nih.gov', 'cdc.gov', 'who.int',
                'fda.gov', 'epa.gov', 'nsf.gov'
            ],
            'encyclopedia': [
                'wikipedia.org', 'britannica.com', 'encyclopedia.com'
            ],
            'medical': [
                'mayoclinic.org', 'webmd.com', 'healthline.com',
                'medlineplus.gov', 'uptodate.com'
            ]
        }
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì†ŒìŠ¤ë“¤
        self.suspicious_sources = [
            'conspiracy.com', 'truth.com', 'realnews.com',
            'alternative.com', 'hidden.com', 'secret.com',
            'infowars.com', 'naturalnews.com'
        ]
        
        # ì‚¬ì‹¤ ê²€ì¦ íŒ¨í„´ë“¤
        self.verification_patterns = {
            'scientific_facts': {
                'patterns': [
                    r'ì§€êµ¬.*êµ¬í˜•|ì§€êµ¬.*ë‘¥ê¸€', r'ë¬¼.*100ë„.*ë“', r'1\s*\+\s*1\s*=\s*2',
                    r'íƒœì–‘.*ì¤‘ì‹¬', r'ì¤‘ë ¥.*ì¡´ì¬', r'DNA.*êµ¬ì¡°', r'ì§„í™”.*ì´ë¡ '
                ],
                'weight': 0.9
            },
            'historical_facts': {
                'patterns': [
                    r'ì„¸ê³„ëŒ€ì „.*ë°œìƒ', r'ì¸ë¥˜.*ì§„í™”', r'ë¬¸ëª….*ë°œì „',
                    r'ì—­ì‚¬.*ê¸°ë¡', r'ê³ ê³ í•™.*ë°œê²¬'
                ],
                'weight': 0.8
            },
            'medical_facts': {
                'patterns': [
                    r'ë°±ì‹ .*íš¨ê³¼', r'ì„¸ê· .*ì§ˆë³‘', r'ì˜í•™.*ë°œì „',
                    r'ì¹˜ë£Œ.*ë°©ë²•', r'ì˜ˆë°©.*ìˆ˜ë‹¨'
                ],
                'weight': 0.85
            }
        }
        
        # ì‹ ë¢°ë„ ì§€í‘œë“¤
        self.credibility_indicators = {
            'positive': [
                'ì—°êµ¬ì— ë”°ë¥´ë©´', 'ê³¼í•™ì ìœ¼ë¡œ', 'í†µê³„ì ìœ¼ë¡œ', 'ì‹¤í—˜ ê²°ê³¼',
                'ì „ë¬¸ê°€ê°€', 'í•™ìˆ ì ìœ¼ë¡œ', 'ê²€ì¦ëœ', 'ì…ì¦ëœ', 'ë…¼ë¬¸ì—ì„œ',
                'peer-reviewed', 'scientific study', 'research shows'
            ],
            'negative': [
                'í™•ì‹¤íˆ', '100%', 'ì ˆëŒ€ì ìœ¼ë¡œ', 'ì˜ì‹¬ì˜ ì—¬ì§€ê°€ ì—†ë‹¤',
                'ìˆ¨ê²¨ì§„ ì§„ì‹¤', 'ìŒëª¨ë¡ ', 'ì •ë¶€ê°€ ìˆ¨ê¸´', 'ê±°ì§“ë§',
                'conspiracy', 'hidden truth', 'cover-up'
            ]
        }
        
        # í—¤ë” ì„¤ì •
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
    
    def research_question(self, question: str, max_sources: int = 10) -> ResearchAnswer:
        """ì§ˆë¬¸ì— ëŒ€í•œ ê³ ê¸‰ ì—°êµ¬ ìˆ˜í–‰"""
        logger.info(f"ê³ ê¸‰ ì—°êµ¬ ì‹œì‘: {question}")
        
        # 1. ì§ˆë¬¸ ë¶„ì„ ë° ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½
        search_strategy = self._analyze_question(question)
        
        # 2. ë‹¤ì¤‘ ê²€ìƒ‰ ìˆ˜í–‰
        all_results = []
        for keyword in search_strategy['keywords']:
            results = self._perform_web_search(keyword, max_results=5)
            all_results.extend(results)
        
        # 3. ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        unique_results = self._deduplicate_results(all_results)
        
        # 4. ì‹ ë¢°ë„ ë° ê´€ë ¨ì„± í‰ê°€
        evaluated_results = self._evaluate_results(unique_results, question)
        
        # 5. ìƒìœ„ ì†ŒìŠ¤ ì„ íƒ
        top_results = sorted(evaluated_results, key=lambda x: x.credibility_score, reverse=True)[:max_sources]
        
        # 6. ì‚¬ì‹¤ ê²€ì¦ ìˆ˜í–‰
        fact_verifications = self._verify_facts(top_results, question)
        
        # 7. ë‹µë³€ ìƒì„±
        answer, confidence, reasoning, limitations = self._generate_comprehensive_answer(
            question, top_results, fact_verifications
        )
        
        return ResearchAnswer(
            question=question,
            answer=answer,
            confidence=confidence,
            sources=top_results,
            fact_verifications=fact_verifications,
            reasoning=reasoning,
            limitations=limitations,
            timestamp=datetime.now()
        )
    
    def _analyze_question(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë¶„ì„ ë° ê²€ìƒ‰ ì „ëµ ìˆ˜ë¦½"""
        # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
        question_types = []
        if any(word in question for word in ['ë¬´ì—‡', 'ë­', 'what']):
            question_types.append('definition')
        if any(word in question for word in ['ì–¸ì œ', 'when']):
            question_types.append('temporal')
        if any(word in question for word in ['ì–´ë””', 'where']):
            question_types.append('location')
        if any(word in question for word in ['ì™œ', 'why']):
            question_types.append('causal')
        if any(word in question for word in ['ì–´ë–»ê²Œ', 'how']):
            question_types.append('process')
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
        keywords = [question]
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í‚¤ì›Œë“œ ì¶”ê°€
        if 'definition' in question_types:
            keywords.append(question + ' ì •ì˜ ì˜ë¯¸')
        if 'temporal' in question_types:
            keywords.append(question + ' ë‚ ì§œ ì‹œê°„')
        if 'location' in question_types:
            keywords.append(question + ' ìœ„ì¹˜ ì¥ì†Œ')
        if 'causal' in question_types:
            keywords.append(question + ' ì´ìœ  ì›ì¸')
        if 'process' in question_types:
            keywords.append(question + ' ë°©ë²• ê³¼ì •')
        
        # ì˜ì–´ í‚¤ì›Œë“œ ì¶”ê°€
        if not any(ord(char) > 127 for char in question):
            keywords.append(question + ' facts information research')
        
        return {
            'types': question_types,
            'keywords': keywords[:5],  # ìƒìœ„ 5ê°œë§Œ ì‚¬ìš©
            'complexity': len(question.split()) / 10.0
        }
    
    def _perform_web_search(self, query: str, max_results: int = 5) -> List[WebSearchResult]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰"""
        results = []
        
        # ì‹¤ì œ ê²€ìƒ‰ ì—”ì§„ë“¤ ì‹œë®¬ë ˆì´ì…˜
        search_engines = ['google', 'bing', 'duckduckgo']
        
        for engine in search_engines:
            try:
                engine_results = self._search_with_engine(engine, query, max_results)
                results.extend(engine_results)
                time.sleep(0.5)  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            except Exception as e:
                logger.warning(f"{engine} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        return results
    
    def _search_with_engine(self, engine: str, query: str, max_results: int) -> List[WebSearchResult]:
        """íŠ¹ì • ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ ê²€ìƒ‰"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ê° ê²€ìƒ‰ ì—”ì§„ì˜ APIë¥¼ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ ê²°ê³¼ë¥¼ ë°˜í™˜
        
        mock_results = self._generate_mock_results(query, max_results)
        
        results = []
        for mock in mock_results:
            # ì‹¤ì œ ì›¹ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹œë®¬ë ˆì´ì…˜
            content = self._fetch_web_content(mock['url'])
            
            results.append(WebSearchResult(
                title=mock['title'],
                url=mock['url'],
                content=content,
                snippet=mock['snippet'],
                domain=mock['domain'],
                credibility_score=0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                relevance_score=0.0,    # ë‚˜ì¤‘ì— ê³„ì‚°
                fact_check_score=0.0,   # ë‚˜ì¤‘ì— ê³„ì‚°
                timestamp=datetime.now()
            ))
        
        return results
    
    def _generate_mock_results(self, query: str, max_results: int) -> List[Dict[str, str]]:
        """ì‹œë®¬ë ˆì´ì…˜ëœ ê²€ìƒ‰ ê²°ê³¼ ìƒì„±"""
        # ì‹¤ì œë¡œëŠ” ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
        mock_results = []
        
        # ë‹¤ì–‘í•œ ì†ŒìŠ¤ íƒ€ì…ì˜ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        source_templates = [
            {
                'title': f'{query} - Wikipedia',
                'url': f'https://ko.wikipedia.org/wiki/{quote(query)}',
                'snippet': f'{query}ì— ëŒ€í•œ ìƒì„¸í•œ ì •ë³´ê°€ ìœ„í‚¤í”¼ë””ì•„ì— ìˆìŠµë‹ˆë‹¤.',
                'domain': 'wikipedia.org'
            },
            {
                'title': f'{query} ê´€ë ¨ ì—°êµ¬ - Nature',
                'url': f'https://www.nature.com/articles/{quote(query)}',
                'snippet': f'{query}ì— ëŒ€í•œ ìµœì‹  ê³¼í•™ ì—°êµ¬ ê²°ê³¼ì…ë‹ˆë‹¤.',
                'domain': 'nature.com'
            },
            {
                'title': f'{query} ë‰´ìŠ¤ - BBC',
                'url': f'https://www.bbc.com/news/{quote(query)}',
                'snippet': f'{query}ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ì™€ ë¶„ì„ì…ë‹ˆë‹¤.',
                'domain': 'bbc.com'
            },
            {
                'title': f'{query} ì˜í•™ ì •ë³´ - Mayo Clinic',
                'url': f'https://www.mayoclinic.org/{quote(query)}',
                'snippet': f'{query}ì— ëŒ€í•œ ì˜í•™ì  ì •ë³´ì™€ ì¹˜ë£Œë²•ì…ë‹ˆë‹¤.',
                'domain': 'mayoclinic.org'
            },
            {
                'title': f'{query} - Scientific American',
                'url': f'https://www.scientificamerican.com/{quote(query)}',
                'snippet': f'{query}ì— ëŒ€í•œ ê³¼í•™ì  ì„¤ëª…ê³¼ ë¶„ì„ì…ë‹ˆë‹¤.',
                'domain': 'scientificamerican.com'
            }
        ]
        
        # ëœë¤í•˜ê²Œ ì„ íƒí•˜ì—¬ ë°˜í™˜
        selected = random.sample(source_templates, min(max_results, len(source_templates)))
        return selected
    
    def _fetch_web_content(self, url: str) -> str:
        """ì›¹ í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ì‹¤ì œë¡œëŠ” requestsë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜´
            # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            for script in soup(["script", "style"]):
                script.decompose()
            
            text = soup.get_text()
            return text[:2000]  # ì²˜ìŒ 2000ìë§Œ ì‚¬ìš©
            
        except Exception as e:
            logger.warning(f"ì›¹ í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {url}: {e}")
            return f"ì›¹ í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {url}"
    
    def _deduplicate_results(self, results: List[WebSearchResult]) -> List[WebSearchResult]:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        seen_urls = set()
        unique_results = []
        
        for result in results:
            if result.url not in seen_urls:
                seen_urls.add(result.url)
                unique_results.append(result)
        
        return unique_results
    
    def _evaluate_results(self, results: List[WebSearchResult], question: str) -> List[WebSearchResult]:
        """ê²€ìƒ‰ ê²°ê³¼ í‰ê°€"""
        for result in results:
            # ë„ë©”ì¸ ì‹ ë¢°ë„
            domain_credibility = self._calculate_domain_credibility(result.domain)
            
            # ë‚´ìš© ì‹ ë¢°ë„
            content_credibility = self._calculate_content_credibility(result.content)
            
            # ê´€ë ¨ì„± ì ìˆ˜
            relevance_score = self._calculate_relevance(result, question)
            
            # ì‚¬ì‹¤ ê²€ì¦ ì ìˆ˜
            fact_check_score = self._calculate_fact_check_score(result.content)
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            result.credibility_score = (
                domain_credibility * 0.4 +
                content_credibility * 0.3 +
                relevance_score * 0.2 +
                fact_check_score * 0.1
            )
            result.relevance_score = relevance_score
            result.fact_check_score = fact_check_score
        
        return results
    
    def _calculate_domain_credibility(self, domain: str) -> float:
        """ë„ë©”ì¸ ì‹ ë¢°ë„ ê³„ì‚°"""
        for category, sources in self.credible_sources.items():
            if domain in sources:
                if category == 'academic':
                    return 0.95
                elif category == 'government':
                    return 0.9
                elif category == 'news':
                    return 0.8
                elif category == 'encyclopedia':
                    return 0.75
                elif category == 'medical':
                    return 0.85
        
        if domain in self.suspicious_sources:
            return 0.1
        
        # ë„ë©”ì¸ í™•ì¥ì ê¸°ë°˜ í‰ê°€
        if domain.endswith('.edu'):
            return 0.9
        elif domain.endswith('.gov'):
            return 0.85
        elif domain.endswith('.org'):
            return 0.7
        elif domain.endswith('.com'):
            return 0.6
        else:
            return 0.5
    
    def _calculate_content_credibility(self, content: str) -> float:
        """ë‚´ìš© ì‹ ë¢°ë„ ê³„ì‚°"""
        credibility = 0.5
        
        # ê¸ì •ì  ì§€í‘œë“¤
        for indicator in self.credibility_indicators['positive']:
            if indicator in content.lower():
                credibility += 0.05
        
        # ë¶€ì •ì  ì§€í‘œë“¤
        for indicator in self.credibility_indicators['negative']:
            if indicator in content.lower():
                credibility -= 0.1
        
        # ê¸¸ì´ ê¸°ë°˜ í‰ê°€ (ë„ˆë¬´ ì§§ê±°ë‚˜ ë„ˆë¬´ ê¸¸ë©´ ì˜ì‹¬)
        content_length = len(content)
        if 100 < content_length < 5000:
            credibility += 0.1
        elif content_length < 50 or content_length > 10000:
            credibility -= 0.1
        
        return max(0.0, min(1.0, credibility))
    
    def _calculate_relevance(self, result: WebSearchResult, question: str) -> float:
        """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        question_words = set(question.lower().split())
        title_words = set(result.title.lower().split())
        snippet_words = set(result.snippet.lower().split())
        
        # ì œëª©ê³¼ ì§ˆë¬¸ì˜ ë‹¨ì–´ ê²¹ì¹¨
        title_overlap = len(question_words.intersection(title_words)) / len(question_words)
        
        # ìŠ¤ë‹ˆí«ê³¼ ì§ˆë¬¸ì˜ ë‹¨ì–´ ê²¹ì¹¨
        snippet_overlap = len(question_words.intersection(snippet_words)) / len(question_words)
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        relevance = (title_overlap * 0.6 + snippet_overlap * 0.4)
        
        return min(1.0, relevance)
    
    def _calculate_fact_check_score(self, content: str) -> float:
        """ì‚¬ì‹¤ ê²€ì¦ ì ìˆ˜ ê³„ì‚°"""
        total_score = 0.0
        total_weight = 0.0
        
        for category, data in self.verification_patterns.items():
            patterns = data['patterns']
            weight = data['weight']
            
            for pattern in patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    total_score += weight
                    total_weight += 1.0
        
        if total_weight == 0:
            return 0.5  # ì¤‘ë¦½ ì ìˆ˜
        
        return total_score / total_weight
    
    def _verify_facts(self, results: List[WebSearchResult], question: str) -> List[FactVerification]:
        """ì‚¬ì‹¤ ê²€ì¦ ìˆ˜í–‰"""
        verifications = []
        
        for result in results:
            if result.fact_check_score > 0.7:  # ë†’ì€ ì‚¬ì‹¤ ê²€ì¦ ì ìˆ˜
                verification = FactVerification(
                    statement=result.snippet,
                    is_verified=True,
                    confidence=result.fact_check_score,
                    evidence=[f"íŒ¨í„´ ë§¤ì¹­: {result.title}"],
                    contradictory_evidence=[],
                    verification_method="pattern_matching",
                    source_diversity=1
                )
                verifications.append(verification)
        
        return verifications
    
    def _generate_comprehensive_answer(self, question: str, sources: List[WebSearchResult], 
                                     fact_verifications: List[FactVerification]) -> Tuple[str, float, str, List[str]]:
        """ì¢…í•©ì ì¸ ë‹µë³€ ìƒì„±"""
        if not sources:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì´ ì§ˆë¬¸ì— ëŒ€í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 0.0, "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŒ", ["ì •ë³´ ë¶€ì¡±"]
        
        # ì‹ ë¢°ë„ê°€ ë†’ì€ ì†ŒìŠ¤ë“¤ë§Œ ì‚¬ìš©
        reliable_sources = [s for s in sources if s.credibility_score > 0.7]
        
        if not reliable_sources:
            return "ì°¾ì€ ì •ë³´ì˜ ì‹ ë¢°ë„ê°€ ë‚®ì•„ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.", 0.3, "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ ë¶€ì¡±", ["ì‹ ë¢°ë„ ë‚®ìŒ"]
        
        # ë‹µë³€ êµ¬ì„±
        answer_parts = []
        confidence_scores = []
        limitations = []
        
        # ì£¼ìš” ë‹µë³€
        answer_parts.append(f"ì§ˆë¬¸: {question}")
        answer_parts.append("\në‹µë³€:")
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë“¤ì˜ ì •ë³´ í†µí•©
        for i, source in enumerate(reliable_sources[:3], 1):
            answer_parts.append(f"{i}. {source.snippet}")
            confidence_scores.append(source.credibility_score)
        
        # ì‚¬ì‹¤ ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        if fact_verifications:
            verified_count = len([v for v in fact_verifications if v.is_verified])
            answer_parts.append(f"\nê²€ì¦ëœ ì‚¬ì‹¤: {verified_count}ê°œ í•­ëª© í™•ì¸ë¨")
            confidence_scores.append(0.9)
        
        # ì†ŒìŠ¤ ì •ë³´
        answer_parts.append(f"\nì°¸ê³  ì†ŒìŠ¤:")
        for source in reliable_sources[:3]:
            answer_parts.append(f"â€¢ {source.title} (ì‹ ë¢°ë„: {source.credibility_score:.2f})")
        
        answer = "\n".join(answer_parts)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.5
        
        # ì¶”ë¡  ê³¼ì •
        reasoning = f"ì´ {len(sources)}ê°œì˜ ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë©°, ê·¸ ì¤‘ {len(reliable_sources)}ê°œì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        
        # í•œê³„ì 
        if len(reliable_sources) < 3:
            limitations.append("ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ê°€ ë¶€ì¡±í•¨")
        if avg_confidence < 0.8:
            limitations.append("ì •ë³´ì˜ ì‹ ë¢°ë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ")
        if not fact_verifications:
            limitations.append("ì‚¬ì‹¤ ê²€ì¦ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ")
        
        return answer, avg_confidence, reasoning, limitations

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” AI ê³ ê¸‰ ì›¹ ì—°êµ¬ì› ì‹œì‘")
    print("=" * 60)
    
    researcher = AIAdvancedResearcher()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ì§€êµ¬ëŠ” ë‘¥ê¸€ê¹Œìš”?",
        "ë¬¼ì€ ëª‡ ë„ì—ì„œ ë“ë‚˜ìš”?",
        "ì½”ë¡œë‚˜19ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì¸ê³µì§€ëŠ¥ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?",
        "ê¸°í›„ë³€í™”ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    for question in test_questions:
        print(f"\nâ“ ì§ˆë¬¸: {question}")
        print("-" * 40)
        
        try:
            result = researcher.research_question(question)
            
            print(f"ğŸ’¡ ë‹µë³€:\n{result.answer}")
            print(f"\nğŸ¯ ì‹ ë¢°ë„: {result.confidence:.2f}")
            print(f"ğŸ” ì¶”ë¡ : {result.reasoning}")
            print(f"ğŸ“š ì†ŒìŠ¤ ìˆ˜: {len(result.sources)}ê°œ")
            print(f"âœ… ì‚¬ì‹¤ ê²€ì¦: {len(result.fact_verifications)}ê°œ")
            
            if result.limitations:
                print(f"âš ï¸ í•œê³„ì : {', '.join(result.limitations)}")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        print("=" * 60)
        time.sleep(2)

if __name__ == "__main__":
    main()

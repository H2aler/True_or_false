#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Confidence System
ê³ ê¸‰ ì‹ ë¢°ë„ í‰ê°€ ì‹œìŠ¤í…œ

ChatGPT/Claude ìˆ˜ì¤€ì˜ ë‹¤ì¸µì  ì‹ ë¢°ë„ í‰ê°€ì™€ í’ˆì§ˆ ë³´ì¦ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import re
import json
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
import statistics
import math
from collections import defaultdict
import asyncio
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ConfidenceSource(Enum):
    """ì‹ ë¢°ë„ ì†ŒìŠ¤"""
    INPUT_VALIDATION = "input_validation"
    CONTENT_ANALYSIS = "content_analysis"
    CONTEXT_RELEVANCE = "context_relevance"
    PROCESSING_SUCCESS = "processing_success"
    RESPONSE_QUALITY = "response_quality"
    CONSISTENCY = "consistency"
    EXPERTISE = "expertise"
    EVIDENCE = "evidence"

class QualityLevel(Enum):
    """í’ˆì§ˆ ìˆ˜ì¤€"""
    POOR = 0.0
    FAIR = 0.25
    GOOD = 0.5
    VERY_GOOD = 0.75
    EXCELLENT = 0.95
    PERFECT = 1.0

@dataclass
class ConfidenceScore:
    """ì‹ ë¢°ë„ ì ìˆ˜"""
    overall: float
    sources: Dict[ConfidenceSource, float]
    quality_level: QualityLevel
    explanation: str
    recommendations: List[str]
    timestamp: datetime
    processing_time: float

@dataclass
class QualityMetrics:
    """í’ˆì§ˆ ì§€í‘œ"""
    accuracy: float
    completeness: float
    consistency: float
    relevance: float
    clarity: float
    reliability: float
    timeliness: float
    usability: float

class AdvancedConfidenceSystem:
    """ê³ ê¸‰ ì‹ ë¢°ë„ í‰ê°€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.confidence_weights = self._initialize_confidence_weights()
        self.quality_thresholds = self._initialize_quality_thresholds()
        self.expertise_patterns = self._initialize_expertise_patterns()
        self.evidence_patterns = self._initialize_evidence_patterns()
        self.consistency_history = defaultdict(list)
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    def _initialize_confidence_weights(self) -> Dict[ConfidenceSource, float]:
        """ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        return {
            ConfidenceSource.INPUT_VALIDATION: 0.15,
            ConfidenceSource.CONTENT_ANALYSIS: 0.20,
            ConfidenceSource.CONTEXT_RELEVANCE: 0.15,
            ConfidenceSource.PROCESSING_SUCCESS: 0.15,
            ConfidenceSource.RESPONSE_QUALITY: 0.15,
            ConfidenceSource.CONSISTENCY: 0.10,
            ConfidenceSource.EXPERTISE: 0.05,
            ConfidenceSource.EVIDENCE: 0.05
        }
    
    def _initialize_quality_thresholds(self) -> Dict[QualityLevel, float]:
        """í’ˆì§ˆ ì„ê³„ê°’ ì´ˆê¸°í™”"""
        return {
            QualityLevel.POOR: 0.0,
            QualityLevel.FAIR: 0.25,
            QualityLevel.GOOD: 0.5,
            QualityLevel.VERY_GOOD: 0.75,
            QualityLevel.EXCELLENT: 0.95,
            QualityLevel.PERFECT: 1.0
        }
    
    def _initialize_expertise_patterns(self) -> Dict[str, List[str]]:
        """ì „ë¬¸ì„± íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            'scientific': [
                r'ì—°êµ¬ì—\s+ë”°ë¥´ë©´', r'ì‹¤í—˜\s+ê²°ê³¼', r'ê³¼í•™ì ìœ¼ë¡œ\s+ì…ì¦ëœ',
                r'í†µê³„ì ìœ¼ë¡œ\s+ì˜ë¯¸ìˆëŠ”', r'peer\s+reviewed', r'í•™ìˆ \s+ë…¼ë¬¸'
            ],
            'technical': [
                r'ê¸°ìˆ ì ìœ¼ë¡œ\s+ê²€ì¦ëœ', r'ì†ŒìŠ¤\s+ì½”ë“œ', r'ì•Œê³ ë¦¬ì¦˜',
                r'í”„ë¡œí† ì½œ', r'API\s+ë¬¸ì„œ', r'ê¸°ìˆ \s+ëª…ì„¸ì„œ'
            ],
            'medical': [
                r'ì˜í•™ì ìœ¼ë¡œ\s+ì…ì¦ëœ', r'ì„ìƒ\s+ì‹œí—˜', r'FDA\s+ìŠ¹ì¸',
                r'ì˜ë£Œì§„\s+ê¶Œê³ ', r'ì˜í•™\s+ë…¼ë¬¸', r'ì§„ë£Œ\s+ì§€ì¹¨'
            ],
            'legal': [
                r'ë²•ë¥ ì—\s+ë”°ë¥´ë©´', r'ë²•ì›\s+íŒê²°', r'ë²•ë ¹',
                r'ë²•ì \s+ê·¼ê±°', r'ë²•ë¥ \s+ì¡°ë¬¸', r'ë²•ì \s+í•´ì„'
            ]
        }
    
    def _initialize_evidence_patterns(self) -> List[str]:
        """ì¦ê±° íŒ¨í„´ ì´ˆê¸°í™”"""
        return [
            r'ì¶œì²˜:', r'ì°¸ê³ ë¬¸í—Œ:', r'ê·¼ê±°:', r'ì¦ê±°:',
            r'http[s]?://', r'www\.', r'\.com', r'\.org', r'\.edu',
            r'\[.*?\]', r'\(.*?\)', r'ì¸ìš©:', r'ì¸ìš©ë¬¸:'
        ]
    
    async def evaluate_confidence(self, 
                                statement: str, 
                                context: str = "", 
                                analysis_result: Dict[str, Any] = None,
                                validation_result: Dict[str, Any] = None) -> ConfidenceScore:
        """ì‹ ë¢°ë„ í‰ê°€"""
        start_time = datetime.now()
        
        try:
            # ê° ì†ŒìŠ¤ë³„ ì‹ ë¢°ë„ í‰ê°€
            source_scores = {}
            
            # 1. ì…ë ¥ ê²€ì¦ ì‹ ë¢°ë„
            source_scores[ConfidenceSource.INPUT_VALIDATION] = await self._evaluate_input_validation(validation_result)
            
            # 2. ë‚´ìš© ë¶„ì„ ì‹ ë¢°ë„
            source_scores[ConfidenceSource.CONTENT_ANALYSIS] = await self._evaluate_content_analysis(statement, analysis_result)
            
            # 3. ë§¥ë½ ê´€ë ¨ì„± ì‹ ë¢°ë„
            source_scores[ConfidenceSource.CONTEXT_RELEVANCE] = await self._evaluate_context_relevance(statement, context)
            
            # 4. ì²˜ë¦¬ ì„±ê³µ ì‹ ë¢°ë„
            source_scores[ConfidenceSource.PROCESSING_SUCCESS] = await self._evaluate_processing_success(analysis_result)
            
            # 5. ì‘ë‹µ í’ˆì§ˆ ì‹ ë¢°ë„
            source_scores[ConfidenceSource.RESPONSE_QUALITY] = await self._evaluate_response_quality(statement, analysis_result)
            
            # 6. ì¼ê´€ì„± ì‹ ë¢°ë„
            source_scores[ConfidenceSource.CONSISTENCY] = await self._evaluate_consistency(statement, analysis_result)
            
            # 7. ì „ë¬¸ì„± ì‹ ë¢°ë„
            source_scores[ConfidenceSource.EXPERTISE] = await self._evaluate_expertise(statement, context)
            
            # 8. ì¦ê±° ì‹ ë¢°ë„
            source_scores[ConfidenceSource.EVIDENCE] = await self._evaluate_evidence(statement, analysis_result)
            
            # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
            overall_confidence = self._calculate_overall_confidence(source_scores)
            
            # í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì •
            quality_level = self._determine_quality_level(overall_confidence)
            
            # ì„¤ëª… ë° ê¶Œì¥ì‚¬í•­ ìƒì„±
            explanation = self._generate_explanation(source_scores, overall_confidence)
            recommendations = self._generate_recommendations(source_scores, overall_confidence)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return ConfidenceScore(
                overall=overall_confidence,
                sources=source_scores,
                quality_level=quality_level,
                explanation=explanation,
                recommendations=recommendations,
                timestamp=datetime.now(),
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"ì‹ ë¢°ë„ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return ConfidenceScore(
                overall=0.0,
                sources={},
                quality_level=QualityLevel.POOR,
                explanation=f"ì‹ ë¢°ë„ í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                recommendations=["ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."],
                timestamp=datetime.now(),
                processing_time=processing_time
            )
    
    async def _evaluate_input_validation(self, validation_result: Dict[str, Any]) -> float:
        """ì…ë ¥ ê²€ì¦ ì‹ ë¢°ë„ í‰ê°€"""
        if not validation_result:
            return 0.5  # ì¤‘ê°„ê°’
        
        if validation_result.get('is_valid', False):
            base_score = 0.9
        else:
            base_score = 0.3
        
        # ì˜¤ë¥˜ ë° ê²½ê³ ì— ë”°ë¥¸ ê°ì 
        error_penalty = len(validation_result.get('errors', [])) * 0.1
        warning_penalty = len(validation_result.get('warnings', [])) * 0.05
        
        return max(0.0, min(1.0, base_score - error_penalty - warning_penalty))
    
    async def _evaluate_content_analysis(self, statement: str, analysis_result: Dict[str, Any]) -> float:
        """ë‚´ìš© ë¶„ì„ ì‹ ë¢°ë„ í‰ê°€"""
        if not analysis_result:
            return 0.5
        
        # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ í‰ê°€
        truth_percentage = analysis_result.get('final_analysis', {}).get('truth_percentage', 0.5)
        confidence = analysis_result.get('final_analysis', {}).get('confidence', 0.5)
        
        # ë‚´ìš© í’ˆì§ˆ í‰ê°€
        content_quality = self._assess_content_quality(statement)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        return (truth_percentage * 0.4 + confidence * 0.3 + content_quality * 0.3)
    
    async def _evaluate_context_relevance(self, statement: str, context: str) -> float:
        """ë§¥ë½ ê´€ë ¨ì„± ì‹ ë¢°ë„ í‰ê°€"""
        if not context:
            return 0.7  # ë§¥ë½ì´ ì—†ìœ¼ë©´ ì¤‘ê°„ê°’
        
        # ë‹¨ì–´ ìœ ì‚¬ë„ ê³„ì‚°
        statement_words = set(statement.lower().split())
        context_words = set(context.lower().split())
        
        if not statement_words or not context_words:
            return 0.5
        
        # Jaccard ìœ ì‚¬ë„
        intersection = statement_words.intersection(context_words)
        union = statement_words.union(context_words)
        jaccard_similarity = len(intersection) / len(union) if union else 0
        
        # ì˜ë¯¸ì  ê´€ë ¨ì„± í‰ê°€
        semantic_relevance = self._assess_semantic_relevance(statement, context)
        
        return (jaccard_similarity * 0.6 + semantic_relevance * 0.4)
    
    async def _evaluate_processing_success(self, analysis_result: Dict[str, Any]) -> float:
        """ì²˜ë¦¬ ì„±ê³µ ì‹ ë¢°ë„ í‰ê°€"""
        if not analysis_result:
            return 0.0
        
        # ë¶„ì„ ê²°ê³¼ì˜ ì™„ì„±ë„ í‰ê°€
        completeness_score = self._assess_analysis_completeness(analysis_result)
        
        # ì˜¤ë¥˜ ì—¬ë¶€ í™•ì¸
        has_errors = any('error' in str(value).lower() for value in analysis_result.values())
        error_penalty = 0.3 if has_errors else 0.0
        
        return max(0.0, min(1.0, completeness_score - error_penalty))
    
    async def _evaluate_response_quality(self, statement: str, analysis_result: Dict[str, Any]) -> float:
        """ì‘ë‹µ í’ˆì§ˆ ì‹ ë¢°ë„ í‰ê°€"""
        # ë¬¸ì¥ êµ¬ì¡° í’ˆì§ˆ
        structure_quality = self._assess_structure_quality(statement)
        
        # ë¶„ì„ ê²°ê³¼ì˜ ìƒì„¸ë„
        detail_quality = self._assess_detail_quality(analysis_result)
        
        # êµì • í’ˆì§ˆ
        correction_quality = self._assess_correction_quality(analysis_result)
        
        return (structure_quality * 0.4 + detail_quality * 0.3 + correction_quality * 0.3)
    
    async def _evaluate_consistency(self, statement: str, analysis_result: Dict[str, Any]) -> float:
        """ì¼ê´€ì„± ì‹ ë¢°ë„ í‰ê°€"""
        # ì´ì „ ë¶„ì„ ê²°ê³¼ì™€ì˜ ì¼ê´€ì„±
        statement_hash = hash(statement)
        if statement_hash in self.consistency_history:
            previous_scores = self.consistency_history[statement_hash]
            if previous_scores:
                current_score = analysis_result.get('final_analysis', {}).get('truth_percentage', 0.5)
                variance = statistics.stdev([current_score] + previous_scores)
                consistency_score = max(0.0, 1.0 - variance)
            else:
                consistency_score = 0.8
        else:
            consistency_score = 0.8
        
        # í˜„ì¬ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        current_score = analysis_result.get('final_analysis', {}).get('truth_percentage', 0.5)
        self.consistency_history[statement_hash].append(current_score)
        
        # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
        if len(self.consistency_history[statement_hash]) > 10:
            self.consistency_history[statement_hash] = self.consistency_history[statement_hash][-10:]
        
        return consistency_score
    
    async def _evaluate_expertise(self, statement: str, context: str) -> float:
        """ì „ë¬¸ì„± ì‹ ë¢°ë„ í‰ê°€"""
        expertise_score = 0.0
        total_patterns = 0
        
        for domain, patterns in self.expertise_patterns.items():
            domain_score = 0.0
            for pattern in patterns:
                if re.search(pattern, statement + " " + context, re.IGNORECASE):
                    domain_score += 1.0
                total_patterns += 1
            expertise_score += domain_score / len(patterns) if patterns else 0
        
        return expertise_score / len(self.expertise_patterns) if self.expertise_patterns else 0.5
    
    async def _evaluate_evidence(self, statement: str, analysis_result: Dict[str, Any]) -> float:
        """ì¦ê±° ì‹ ë¢°ë„ í‰ê°€"""
        evidence_score = 0.0
        
        # ë¬¸ì¥ ë‚´ ì¦ê±° íŒ¨í„´ ê²€ì‚¬
        for pattern in self.evidence_patterns:
            if re.search(pattern, statement, re.IGNORECASE):
                evidence_score += 0.1
        
        # ë¶„ì„ ê²°ê³¼ì˜ ì¦ê±° í’ˆì§ˆ
        if analysis_result:
            sources = analysis_result.get('sources', [])
            if sources:
                evidence_score += min(0.5, len(sources) * 0.1)
            
            fact_checks = analysis_result.get('fact_checks', [])
            if fact_checks:
                evidence_score += min(0.3, len(fact_checks) * 0.1)
        
        return min(1.0, evidence_score)
    
    def _assess_content_quality(self, statement: str) -> float:
        """ë‚´ìš© í’ˆì§ˆ í‰ê°€"""
        if not statement.strip():
            return 0.0
        
        quality_score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸¸ì´ ì ì ˆì„±
        word_count = len(statement.split())
        if 5 <= word_count <= 100:
            quality_score += 0.2
        elif word_count > 100:
            quality_score += 0.1
        
        # ë¬¸ì¥ êµ¬ì¡°
        sentences = re.split(r'[.!?]+', statement)
        if len(sentences) > 1:
            quality_score += 0.1
        
        # íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©
        if re.search(r'[.,!?;:]', statement):
            quality_score += 0.1
        
        # ëŒ€ì†Œë¬¸ì ì‚¬ìš©
        if re.search(r'[A-Z]', statement) and re.search(r'[a-z]', statement):
            quality_score += 0.1
        
        return min(1.0, quality_score)
    
    def _assess_semantic_relevance(self, statement: str, context: str) -> float:
        """ì˜ë¯¸ì  ê´€ë ¨ì„± í‰ê°€"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ê¸°ë°˜ í‰ê°€
        statement_keywords = set(re.findall(r'\w+', statement.lower()))
        context_keywords = set(re.findall(r'\w+', context.lower()))
        
        if not statement_keywords or not context_keywords:
            return 0.5
        
        # ê³µí†µ í‚¤ì›Œë“œ ë¹„ìœ¨
        common_keywords = statement_keywords.intersection(context_keywords)
        relevance = len(common_keywords) / len(statement_keywords.union(context_keywords))
        
        return relevance
    
    def _assess_analysis_completeness(self, analysis_result: Dict[str, Any]) -> float:
        """ë¶„ì„ ì™„ì„±ë„ í‰ê°€"""
        required_fields = ['final_analysis', 'basic_analysis', 'meta_analysis']
        present_fields = sum(1 for field in required_fields if field in analysis_result)
        
        return present_fields / len(required_fields)
    
    def _assess_structure_quality(self, statement: str) -> float:
        """êµ¬ì¡° í’ˆì§ˆ í‰ê°€"""
        if not statement.strip():
            return 0.0
        
        quality_score = 0.5
        
        # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ
        if statement.strip().endswith(('.', '!', '?')):
            quality_score += 0.2
        
        # ì ì ˆí•œ ê¸¸ì´
        word_count = len(statement.split())
        if 3 <= word_count <= 50:
            quality_score += 0.2
        elif word_count > 50:
            quality_score += 0.1
        
        # ë¬¸ì¥ ì‹œì‘ ëŒ€ë¬¸ì
        if statement.strip()[0].isupper():
            quality_score += 0.1
        
        return min(1.0, quality_score)
    
    def _assess_detail_quality(self, analysis_result: Dict[str, Any]) -> float:
        """ìƒì„¸ë„ í’ˆì§ˆ í‰ê°€"""
        if not analysis_result:
            return 0.0
        
        detail_score = 0.0
        
        # ë¶„ì„ ê²°ê³¼ì˜ ìƒì„¸ë„
        for key, value in analysis_result.items():
            if isinstance(value, dict) and len(value) > 0:
                detail_score += 0.1
            elif isinstance(value, list) and len(value) > 0:
                detail_score += 0.05
        
        return min(1.0, detail_score)
    
    def _assess_correction_quality(self, analysis_result: Dict[str, Any]) -> float:
        """êµì • í’ˆì§ˆ í‰ê°€"""
        if not analysis_result:
            return 0.0
        
        correction_score = 0.5
        
        # êµì • ì œì•ˆ ì¡´ì¬ ì—¬ë¶€
        if analysis_result.get('final_analysis', {}).get('needs_correction', False):
            correction_score += 0.3
        
        # êµì •ëœ ë¬¸ì¥ ì¡´ì¬ ì—¬ë¶€
        if analysis_result.get('final_analysis', {}).get('corrected_statement'):
            correction_score += 0.2
        
        return min(1.0, correction_score)
    
    def _calculate_overall_confidence(self, source_scores: Dict[ConfidenceSource, float]) -> float:
        """ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°"""
        weighted_sum = 0.0
        total_weight = 0.0
        
        for source, score in source_scores.items():
            weight = self.confidence_weights.get(source, 0.1)
            weighted_sum += score * weight
            total_weight += weight
        
        return weighted_sum / total_weight if total_weight > 0 else 0.0
    
    def _determine_quality_level(self, confidence: float) -> QualityLevel:
        """í’ˆì§ˆ ìˆ˜ì¤€ ê²°ì •"""
        for level, threshold in sorted(self.quality_thresholds.items(), key=lambda x: x[1], reverse=True):
            if confidence >= threshold:
                return level
        return QualityLevel.POOR
    
    def _generate_explanation(self, source_scores: Dict[ConfidenceSource, float], overall_confidence: float) -> str:
        """ì„¤ëª… ìƒì„±"""
        explanations = []
        
        # ì „ì²´ ì‹ ë¢°ë„ ì„¤ëª…
        if overall_confidence >= 0.9:
            explanations.append("ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
        elif overall_confidence >= 0.7:
            explanations.append("ë†’ì€ ì‹ ë¢°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
        elif overall_confidence >= 0.5:
            explanations.append("ë³´í†µ ìˆ˜ì¤€ì˜ ì‹ ë¢°ë„ë¥¼ ë³´ì…ë‹ˆë‹¤.")
        else:
            explanations.append("ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
        
        # ì£¼ìš” ê°•ì ê³¼ ì•½ì 
        strengths = [source.value for source, score in source_scores.items() if score >= 0.8]
        weaknesses = [source.value for source, score in source_scores.items() if score < 0.5]
        
        if strengths:
            explanations.append(f"ê°•ì : {', '.join(strengths)}")
        if weaknesses:
            explanations.append(f"ê°œì„  í•„ìš”: {', '.join(weaknesses)}")
        
        return " ".join(explanations)
    
    def _generate_recommendations(self, source_scores: Dict[ConfidenceSource, float], overall_confidence: float) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ì†ŒìŠ¤ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
        if source_scores.get(ConfidenceSource.INPUT_VALIDATION, 0) < 0.5:
            recommendations.append("ì…ë ¥ í˜•ì‹ì„ í™•ì¸í•˜ê³  ì˜¬ë°”ë¥¸ ë°ì´í„°ë¥¼ ì œê³µí•˜ì„¸ìš”.")
        
        if source_scores.get(ConfidenceSource.CONTENT_ANALYSIS, 0) < 0.5:
            recommendations.append("ë‚´ìš©ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê³  ë” ëª…í™•í•œ ë¬¸ì¥ì„ ì‘ì„±í•˜ì„¸ìš”.")
        
        if source_scores.get(ConfidenceSource.CONTEXT_RELEVANCE, 0) < 0.5:
            recommendations.append("ë¬¸ë§¥ê³¼ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.")
        
        if source_scores.get(ConfidenceSource.CONSISTENCY, 0) < 0.5:
            recommendations.append("ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë™ì¼í•œ ì¡°ê±´ì—ì„œ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        
        if source_scores.get(ConfidenceSource.EVIDENCE, 0) < 0.5:
            recommendations.append("ê·¼ê±°ë‚˜ ì¶œì²˜ë¥¼ ì¶”ê°€í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì´ì„¸ìš”.")
        
        # ì „ì²´ì ì¸ ê¶Œì¥ì‚¬í•­
        if overall_confidence < 0.5:
            recommendations.append("ì „ë°˜ì ì¸ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì…ë ¥ ë‚´ìš©ì„ ê²€í† í•˜ì„¸ìš”.")
        
        return recommendations

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ê³ ê¸‰ ì‹ ë¢°ë„ í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    confidence_system = AdvancedConfidenceSystem()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {
            'statement': 'ì§€êµ¬ëŠ” ë‘¥ê¸€ë‹¤.',
            'context': 'ê³¼í•™ì  ì‚¬ì‹¤ì— ëŒ€í•œ ì§ˆë¬¸',
            'analysis_result': {
                'final_analysis': {
                    'truth_percentage': 0.95,
                    'confidence': 0.9,
                    'needs_correction': False
                },
                'sources': [{'title': 'NASA', 'url': 'https://nasa.gov'}],
                'fact_checks': [{'statement': 'ì§€êµ¬ëŠ” êµ¬í˜•', 'is_factual': True}]
            },
            'validation_result': {
                'is_valid': True,
                'errors': [],
                'warnings': []
            }
        },
        {
            'statement': 'ì •ë§ë¡œ ì™„ì „íˆ ì ˆëŒ€ì ìœ¼ë¡œ ëª¨ë“  ê²ƒì´ 100% ì§„ì‹¤ì´ë‹¤.',
            'context': 'ê³¼ì¥ëœ í‘œí˜„ í…ŒìŠ¤íŠ¸',
            'analysis_result': {
                'final_analysis': {
                    'truth_percentage': 0.2,
                    'confidence': 0.3,
                    'needs_correction': True
                }
            },
            'validation_result': {
                'is_valid': True,
                'errors': [],
                'warnings': ['ê³¼ì¥ í‘œí˜„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.']
            }
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{i}. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {test_case['statement']}")
        print("-" * 40)
        
        try:
            # ë¹„ë™ê¸° ì‹ ë¢°ë„ í‰ê°€ ì‹¤í–‰
            import asyncio
            result = asyncio.run(confidence_system.evaluate_confidence(
                test_case['statement'],
                test_case['context'],
                test_case['analysis_result'],
                test_case['validation_result']
            ))
            
            print(f"ì „ì²´ ì‹ ë¢°ë„: {result.overall:.3f}")
            print(f"í’ˆì§ˆ ìˆ˜ì¤€: {result.quality_level.name}")
            print(f"ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.3f}ì´ˆ")
            print(f"ì„¤ëª…: {result.explanation}")
            
            print("\nì†ŒìŠ¤ë³„ ì‹ ë¢°ë„:")
            for source, score in result.sources.items():
                print(f"  {source.value}: {score:.3f}")
            
            if result.recommendations:
                print(f"\nê¶Œì¥ì‚¬í•­:")
                for rec in result.recommendations:
                    print(f"  - {rec}")
                    
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
ë³µí•© ë¬¸ì¥ ë¶„ì„ê¸°
í•˜ë‚˜ì˜ ë¬¸ì¥ì— ì—¬ëŸ¬ ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ë§¥ë½ì´ í¬í•¨ëœ ê²½ìš°ë¥¼ ë¶„ì„
ì˜ˆ: "ê³„ë€ì€ êµ¬í˜•ì´ë‹¤ ì´ ê¸°ê¸°ëŠ” êµ¬í˜•ì´ë‹¤" - ê³„ë€(ê³¼í•™ì ) + ê¸°ê¸°(ì¼ë°˜ë¬¼ì²´)
"""

from ai_truth_detector import TruthDetector, TruthAnalysis
from context_awareness_detector import ContextAwarenessDetector
from typing import List, Dict, Tuple
import re
import logging

logger = logging.getLogger(__name__)

class CompoundSentenceAnalyzer:
    """ë³µí•© ë¬¸ì¥ ë¶„ì„ê¸° - ì—¬ëŸ¬ ë§¥ë½ì´ ì„ì¸ ë¬¸ì¥ì„ ë¶„ì„"""
    
    def __init__(self):
        self.primary_detector = TruthDetector()
        self.context_detector = ContextAwarenessDetector()
        
        # ë¬¸ì¥ ë¶„ë¦¬ íŒ¨í„´
        self.sentence_separators = [
            r'\.\s+',  # ë§ˆì¹¨í‘œ + ê³µë°±
            r'!\s+',   # ëŠë‚Œí‘œ + ê³µë°±
            r'\?\s+',  # ë¬¼ìŒí‘œ + ê³µë°±
            r';\s+',   # ì„¸ë¯¸ì½œë¡  + ê³µë°±
            r'\s+ê·¸ëŸ¬ë¯€ë¡œ\s+',  # ê·¸ëŸ¬ë¯€ë¡œ
            r'\s+í•˜ì§€ë§Œ\s+',    # í•˜ì§€ë§Œ
            r'\s+ê·¸ëŸ°ë°\s+',    # ê·¸ëŸ°ë°
            r'\s+ê·¸ë¦¬ê³ \s+',    # ê·¸ë¦¬ê³ 
            r'\s+ë˜í•œ\s+',      # ë˜í•œ
            r'\s+ë”°ë¼ì„œ\s+',    # ë”°ë¼ì„œ
            r'\s+ì´\s+',        # "ì´" (ì´ ê¸°ê¸°ëŠ”, ì´ ì‚¬ëŒì€ ë“±)
            r'\s+ê·¸\s+',        # "ê·¸" (ê·¸ ê¸°ê¸°ëŠ”, ê·¸ ì‚¬ëŒì€ ë“±)
            r'\s+ì €\s+',        # "ì €" (ì € ê¸°ê¸°ëŠ”, ì € ì‚¬ëŒì€ ë“±)
        ]
        
        # ë³µí•© ë¬¸ì¥ íŒ¨í„´
        self.compound_patterns = {
            'multiple_objects': [
                r'(\w+)ì€\s+(\w+)ì´ë‹¤\s+(\w+)ì€\s+(\w+)ì´ë‹¤',  # AëŠ” Bì´ë‹¤ CëŠ” Dì´ë‹¤
                r'(\w+)ëŠ”\s+(\w+)ì´ë‹¤\s+(\w+)ëŠ”\s+(\w+)ì´ë‹¤',  # AëŠ” Bì´ë‹¤ CëŠ” Dì´ë‹¤
            ],
            'logical_connection': [
                r'(\w+)ì€\s+(\w+)ë‹¤\.\s*ê·¸ëŸ¬ë¯€ë¡œ\s+(\w+)ì€\s+(\w+)ì´ë‹¤',
                r'(\w+)ëŠ”\s+(\w+)ë‹¤\.\s*ê·¸ëŸ¬ë¯€ë¡œ\s+(\w+)ëŠ”\s+(\w+)ì´ë‹¤',
                r'(\w+)ì€\s+(\w+)ë‹¤\.\s*í•˜ì§€ë§Œ\s+(\w+)ì€\s+(\w+)ì´ë‹¤',
                r'(\w+)ëŠ”\s+(\w+)ë‹¤\.\s*í•˜ì§€ë§Œ\s+(\w+)ëŠ”\s+(\w+)ì´ë‹¤',
            ]
        }
    
    def analyze_compound_sentence(self, statement: str, context: str = None) -> Dict:
        """ë³µí•© ë¬¸ì¥ ë¶„ì„"""
        logger.info(f"ë³µí•© ë¬¸ì¥ ë¶„ì„ ì‹œì‘: {statement}...")
        
        # ê¸°ë³¸ ë¶„ì„
        primary_analysis = self.primary_detector.analyze_statement(statement, context)
        
        # ë¬¸ì¥ ë¶„ë¦¬
        sentences = self._split_sentences(statement)
        
        # ë³µí•© ë¬¸ì¥ íŒ¨í„´ ê°ì§€
        compound_type = self._detect_compound_type(statement)
        
        # ê° ë¬¸ì¥ë³„ ë¶„ì„
        sentence_analyses = []
        for sentence in sentences:
            if sentence.strip():
                context_analysis = self.context_detector.analyze_with_context_awareness(sentence.strip(), context)
                sentence_analyses.append({
                    'sentence': sentence.strip(),
                    'context_analysis': context_analysis
                })
        
        # ë³µí•© ë¬¸ì¥ ì§„ì‹¤ì„± ê³„ì‚°
        compound_truth, compound_confidence = self._calculate_compound_truth(sentence_analyses, compound_type)
        
        # ë³µí•© ë¬¸ì¥ êµì •
        corrected_statement, correction_applied = self._apply_compound_correction(statement, sentence_analyses, compound_type)
        
        result = {
            'original_statement': statement,
            'primary_analysis': primary_analysis,
            'compound_type': compound_type,
            'sentences': sentences,
            'sentence_analyses': sentence_analyses,
            'compound_truth_percentage': compound_truth,
            'compound_confidence': compound_confidence,
            'compound_corrected_statement': corrected_statement,
            'compound_correction_applied': correction_applied,
            'compound_warnings': self._generate_compound_warnings(sentence_analyses, compound_type),
            'philosophical_note': "ë³µí•© ë¬¸ì¥ì€ ì—¬ëŸ¬ ë§¥ë½ì„ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë©°, ê° ë¶€ë¶„ì„ ê°œë³„ì ìœ¼ë¡œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤."
        }
        
        logger.info(f"ë³µí•© ë¬¸ì¥ ë¶„ì„ ì™„ë£Œ: {statement}")
        return result
    
    def _split_sentences(self, statement: str) -> List[str]:
        """ë¬¸ì¥ì„ ë¶„ë¦¬"""
        sentences = [statement]  # ê¸°ë³¸ì ìœ¼ë¡œ ì „ì²´ ë¬¸ì¥
        
        # íŠ¹ë³„í•œ íŒ¨í„´ë“¤ ë¨¼ì € ì²˜ë¦¬
        # "AëŠ” Bì´ë‹¤ CëŠ” Dì´ë‹¤" íŒ¨í„´
        multiple_objects_pattern = r'(\w+[ì€ëŠ”])\s+(\w+ì´ë‹¤)\s+(\w+[ì€ëŠ”])\s+(\w+ì´ë‹¤)'
        if re.search(multiple_objects_pattern, statement):
            match = re.search(multiple_objects_pattern, statement)
            if match:
                part1 = match.group(1) + ' ' + match.group(2)
                part2 = match.group(3) + ' ' + match.group(4)
                sentences = [part1.strip(), part2.strip()]
                return sentences
        
        # ì¼ë°˜ì ì¸ ë¶„ë¦¬ íŒ¨í„´ë“¤
        for pattern in self.sentence_separators:
            if re.search(pattern, statement):
                sentences = re.split(pattern, statement)
                sentences = [s.strip() for s in sentences if s.strip()]
                break
        
        return sentences
    
    def _detect_compound_type(self, statement: str) -> str:
        """ë³µí•© ë¬¸ì¥ ìœ í˜• ê°ì§€"""
        for compound_type, patterns in self.compound_patterns.items():
            for pattern in patterns:
                if re.search(pattern, statement):
                    return compound_type
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ì—¬ëŸ¬ ë¬¸ì¥ì´ ìˆìœ¼ë©´ ë³µí•© ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼
        if len(self._split_sentences(statement)) > 1:
            return 'multiple_sentences'
        
        return 'simple'
    
    def _calculate_compound_truth(self, sentence_analyses: List[Dict], compound_type: str) -> Tuple[float, float]:
        """ë³µí•© ë¬¸ì¥ ì§„ì‹¤ì„± ê³„ì‚°"""
        if not sentence_analyses:
            return 0.5, 0.5
        
        # ê° ë¬¸ì¥ì˜ ì§„ì‹¤ì„±ê³¼ ì‹ ë¢°ë„ ìˆ˜ì§‘
        truths = []
        confidences = []
        
        for analysis in sentence_analyses:
            context_analysis = analysis['context_analysis']
            truths.append(context_analysis['context_aware_truth_percentage'])
            confidences.append(context_analysis['context_aware_confidence'])
        
        if compound_type == 'multiple_objects':
            # ì—¬ëŸ¬ ê°ì²´ê°€ ìˆëŠ” ê²½ìš°: ê°ê°ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ê°€ì¤‘ í‰ê· 
            # ê³¼í•™ì  ë§¥ë½ê³¼ ì¼ë°˜ ë¬¼ì²´ ë§¥ë½ì´ ì„ì¸ ê²½ìš° ì°¨ì´ë¥¼ ë°˜ì˜
            if len(truths) >= 2:
                # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ë¬¸ì¥ì˜ ì§„ì‹¤ì„± ì°¨ì´ê°€ í´ ê²½ìš° ì¡°ì •
                truth_diff = abs(truths[0] - truths[1])
                if truth_diff > 0.3:  # 30% ì´ìƒ ì°¨ì´
                    # ë§¥ë½ì´ ë‹¤ë¥¸ ê²½ìš° í‰ê· ì„ ë‚®ì¶¤ (ë¶ˆì¼ì¹˜ í˜ë„í‹°)
                    compound_truth = (sum(truths) / len(truths)) * 0.8
                    compound_confidence = (sum(confidences) / len(confidences)) * 0.7
                else:
                    compound_truth = sum(truths) / len(truths)
                    compound_confidence = sum(confidences) / len(confidences)
            else:
                compound_truth = truths[0]
                compound_confidence = confidences[0]
        
        elif compound_type == 'logical_connection':
            # ë…¼ë¦¬ì  ì—°ê²°ì´ ìˆëŠ” ê²½ìš°: ë…¼ë¦¬ì  ì¼ê´€ì„± ê³ ë ¤
            if len(truths) >= 2:
                # ì „ì œì™€ ê²°ë¡ ì˜ ë…¼ë¦¬ì  ì¼ê´€ì„± í™•ì¸
                premise_truth = truths[0]
                conclusion_truth = truths[1]
                
                # ë…¼ë¦¬ì  ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°
                logical_consistency = 1.0 - abs(premise_truth - conclusion_truth)
                compound_truth = (premise_truth + conclusion_truth) / 2 * logical_consistency
                compound_confidence = (sum(confidences) / len(confidences)) * logical_consistency
            else:
                compound_truth = truths[0]
                compound_confidence = confidences[0]
        
        else:
            # ì¼ë°˜ì ì¸ ë³µí•© ë¬¸ì¥
            compound_truth = sum(truths) / len(truths)
            compound_confidence = sum(confidences) / len(confidences)
        
        return compound_truth, compound_confidence
    
    def _apply_compound_correction(self, statement: str, sentence_analyses: List[Dict], compound_type: str) -> Tuple[str, bool]:
        """ë³µí•© ë¬¸ì¥ êµì • ì ìš©"""
        corrected_parts = []
        correction_applied = False
        
        for analysis in sentence_analyses:
            sentence = analysis['sentence']
            context_analysis = analysis['context_analysis']
            
            if context_analysis['context_correction_applied']:
                corrected_parts.append(context_analysis['context_corrected_statement'])
                correction_applied = True
            else:
                corrected_parts.append(sentence)
        
        if correction_applied:
            # ì›ë˜ ë¬¸ì¥ì˜ ì—°ê²°ì–´ ë³µì›
            corrected_statement = self._restore_connections(statement, corrected_parts)
            return corrected_statement, True
        
        return statement, False
    
    def _restore_connections(self, original: str, corrected_parts: List[str]) -> str:
        """ì›ë˜ ë¬¸ì¥ì˜ ì—°ê²°ì–´ë¥¼ ë³µì›"""
        # ê°„ë‹¨í•œ ë³µì›: ê³µë°±ìœ¼ë¡œ ì—°ê²°
        return ' '.join(corrected_parts)
    
    def _generate_compound_warnings(self, sentence_analyses: List[Dict], compound_type: str) -> List[str]:
        """ë³µí•© ë¬¸ì¥ ê²½ê³  ìƒì„±"""
        warnings = []
        
        if compound_type == 'multiple_objects':
            # ì„œë¡œ ë‹¤ë¥¸ ë§¥ë½ì˜ ê°ì²´ë“¤ì´ ìˆëŠ” ê²½ìš°
            context_types = []
            for analysis in sentence_analyses:
                context_type = analysis['context_analysis'].get('context_type', 'unknown')
                context_types.append(context_type)
            
            if len(set(context_types)) > 1:
                warnings.append("ì„œë¡œ ë‹¤ë¥¸ ë§¥ë½ì˜ ê°ì²´ë“¤ì´ í•˜ë‚˜ì˜ ë¬¸ì¥ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        elif compound_type == 'logical_connection':
            # ë…¼ë¦¬ì  ì—°ê²°ì´ ìˆëŠ” ê²½ìš°
            if len(sentence_analyses) >= 2:
                premise_truth = sentence_analyses[0]['context_analysis']['context_aware_truth_percentage']
                conclusion_truth = sentence_analyses[1]['context_analysis']['context_aware_truth_percentage']
                
                if abs(premise_truth - conclusion_truth) > 0.4:
                    warnings.append("ì „ì œì™€ ê²°ë¡ ì˜ ì§„ì‹¤ì„± ì°¨ì´ê°€ í½ë‹ˆë‹¤. ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        return warnings

def main():
    """ë³µí•© ë¬¸ì¥ ë¶„ì„ê¸° ë°ëª¨"""
    analyzer = CompoundSentenceAnalyzer()
    
    test_statements = [
        'ê³„ë€ì€ êµ¬í˜•ì´ë‹¤ ì´ ê¸°ê¸°ëŠ” êµ¬í˜•ì´ë‹¤',
        'ì‚¬ëŒì€ ê±°ì§“ë§ì„ í•œë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì‚¬ëŒì€ ë‚˜ìœ ì¡´ì¬ì´ë‹¤.',
        'ì‚¬ëŒì€ ì„ ì˜ì˜ ê±°ì§“ë§ì„ í•œë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì‚¬ëŒì€ ì°©í•œ ì¡´ì¬ì´ë‹¤.',
        'ì§€êµ¬ëŠ” êµ¬í˜•ì´ë‹¤ ìë™ì°¨ëŠ” êµ¬í˜•ì´ë‹¤'
    ]
    
    print("ğŸ” ë³µí•© ë¬¸ì¥ ë¶„ì„ê¸° ë°ëª¨")
    print("=" * 50)
    
    for statement in test_statements:
        result = analyzer.analyze_compound_sentence(statement)
        
        print(f"\në¬¸ì¥: {statement}")
        print(f"ë³µí•© ìœ í˜•: {result['compound_type']}")
        print(f"ë¶„ë¦¬ëœ ë¬¸ì¥ ìˆ˜: {len(result['sentences'])}")
        print(f"ë³µí•© ì§„ì‹¤ì„±: {result['compound_truth_percentage']:.1%}")
        print(f"ë³µí•© ì‹ ë¢°ë„: {result['compound_confidence']:.1%}")
        
        if result['compound_correction_applied']:
            print(f"êµì •: {result['compound_corrected_statement']}")
        
        if result['compound_warnings']:
            print(f"ê²½ê³ : {result['compound_warnings'][0]}")

if __name__ == "__main__":
    main()
